file,page,caption,text
1-introduction.pdf,0,"There is no technical content visible on this slide. It contains no concepts, equations, algorithms, or model architectures related to ML or NLP. The slide appears to be a background or title slide without instructional material.","CIS 6930 Special Topics in Large Language Models
Overview & Introduction"
1-introduction.pdf,1,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"". This is an institutional name and not related to any specific ML/NLP technical content, concepts, algorithms, or architectures. There are no technical details to explain on the slide.","2
Introduction about myself
Yuanyuan Lei
Assistant Professor
Department of Computer and Information Science and Engineering
Research Area: Natural Language Processing, Large Language Models
Personal website: https://sites.google.com/view/yuanyuan-lei"
1-introduction.pdf,2,"The slide contains only the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content related to machine learning, natural language processing, algorithms, or related concepts present on this slide.","3
Introduction about the course
Fall 2025, MWF 11:45am ‚Äì 12:35am at CSE E222 
Instructor
‚ñ™Yuanyuan Lei (yuanyuan.lei@ufl.edu)
‚ñ™Office Hours: Friday 1:30pm ‚Äì 2:30pm, Malachowsky Hall 3108, or 
Zoom https://ufl.zoom.us/my/yuanyuan.lei
TA
‚ñ™Zixuan Wang (zwang10@ufl.edu) 
‚ñ™Office Hours: Friday 3pm ‚Äì 4pm, Malachowsky Hall 5200, or Zoom 
https://us05web.zoom.us/j/83030672462?pwd=cgo2rzJOTYX3aGVvc
GHvDzvBIubznQ.1 (Meeting ID: 830 3067 2462 Passcode: 6Utsg9)"
1-introduction.pdf,3,"The text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" is just an institutional title and does not contain any technical content related to machine learning, natural language processing, or related algorithms. There are no concepts, equations, or architectures presented on this slide that pertain to ML or NLP.","4
Outline of this lecture
‚ñ™What is Large Language Models
  (language model, large language model)
‚ñ™Why we study Large Language Models
  (capabilities, limitations)
‚ñ™How will we study Large Language Models
  (course content, grading components etc.)"
1-introduction.pdf,4,"The content in the image is a header or title line reading ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not contain any technical concepts, algorithms, equations, architectures, or relationships relevant to machine learning, natural language processing, or similar fields. Therefore, there is no technical content to explain on this slide.","5
Large Language Models"
1-introduction.pdf,5,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content, concepts, algorithms, equations, or architectures related to machine learning or natural language processing. Therefore, there is no relevant technical material to explain from this slide.","6
Large Language Models
Large Language Models can be your helpful assistant
‚ñ™Writing (draft essays, reports, blog posts, improve language)
‚ñ™Learning (explain concepts, search information, summarize)
‚ñ™Creativity (brainstorm ideas, generate poems)
‚ñ™Even for fun (give recommendations for book, movie, music)
‚ñ™and many ‚Ä¶"
1-introduction.pdf,6,"The content on the slide appears to be just the name of a college, specifically the ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML-related content presented on this slide. Therefore, there is no technical explanation relevant to machine learning or natural language processing to provide.","7
What is Language Models
Language Models (LM) is a probability distribution over sequences of 
tokens. Suppose we have a vocabulary ùëâ of a set of tokens. LM ùëù 
assigns each sequence of tokens ùë§1, ‚Ä¶ , ùë§ùëõ‚ààùëâ a probability
ùëù(ùë§1, ‚Ä¶ , ùë§ùëõ)
This probability intuitively tells us how ‚Äúgood‚Äù a sequence of tokens is.
Example:
p(the, mouse, ate, the, cheese) = 0.02
p(the, cheese, ate, the, mouse) = 0.01
p(mouse, the, the, cheese, ate) = 0.0001"
1-introduction.pdf,7,"The slide contains only the text identification of an institution‚Äî""University of Florida Herbert Wertheim College of Engineering""‚Äîand does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Please provide a different slide or additional content for detailed technical explanation.","8
What is Language Models
LM should have the ability to assign meaningful probability to all 
sequences, which requires sophisticated (but implicit) linguistic abilities 
and world knowledge.
Example:
p(the, mouse, ate, the, cheese) = 0.02 -> higher prob, world knowledge
p(the, cheese, ate, the, mouse) = 0.01
p(mouse, the, the, cheese, ate) = 0.0001 -> ungrammatical, syntactic 
knowledge"
1-introduction.pdf,8,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be an institutional affiliation or title, not technical material.","9
What is Language Models
LM takes a sequence and returns a probability to assess its goodness.
ùëùùë§1, ‚Ä¶ , ùë§ùëõ
= p ùë§1  ‚àó ùëùùë§2 ùë§1  ‚àóùëùùë§3 ùë§1, ùë§2 ‚àó ‚Ä¶ ‚àóùëù(ùë§ùëõ|ùë§1, ùë§2, ‚Ä¶ , ùë§ùëõ‚àí1)
p(cat sat on the mat) = p(cat) * p(sat | cat) * p(on | cat sat) * 
 
 
 
 
p(the | cat sat on) * p(mat | cat sat on the)"
1-introduction.pdf,9,"The slide content is just a text header indicating the university and college name: ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning, natural language processing, algorithms, or architectures.","10
What is Language Models
‚ñ™LM takes a sequence and returns a probability to assess its goodness 
‚ñ™We can also generate a sequence given a LM, usually by generating the 
next tokens given previous tokens"
1-introduction.pdf,10,"The slide contains no technical content related to machine learning or natural language processing. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which indicates an institutional affiliation but no technical concepts, algorithms, equations, or architectures are presented.","11
What is Large Language Models
Model parameters ùúÉ plays an important roles"
1-introduction.pdf,11,"This slide contains no technical content related to ML/NLP concepts, algorithms, equations, architectures, or related topics. It only displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""","12
How large are LLM"
1-introduction.pdf,12,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content, concepts, algorithms, equations, or architectures related to ML or NLP presented on this slide.","13
What is Large Language Models
‚ñ™Small models: under 100 million parameters (useful for lightweight 
tasks, edge devices, or fine-tuning)
‚ñ™Medium models: 100M ‚Äì 1B parameters (comparable to early 
transformer models like BERT-base)
‚ñ™Large models: 1B ‚Äì 10B parameters (often considered ‚Äúlarge‚Äù in many 
research papers).
‚ñ™Very large models: 10B ‚Äì 100B parameters (models like GPT-3 with 
175B fall here).
‚ñ™Frontier-scale models: 100B+ parameters (GPT-4, Claude 3, Gemini 
1.5 Pro, etc.)."
1-introduction.pdf,13,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or other relevant algorithms and concepts. Therefore, there are no technical concepts, algorithms, equations, architectures, or relationships to explain from this slide.","14
Why study Large Language Models
‚ñ™Reason 1: Capability
One single model to solve many NLP tasks
recall conditional generation:"
1-introduction.pdf,14,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be a heading or institutional affiliation and not course or technical material.","15
Why study Large Language Models
‚ñ™Reason 1: Capability
This simple interface opens up the possibility of having a language model 
solve a vast variety of tasks by just changing the prompt."
1-introduction.pdf,15,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and includes no technical content related to machine learning, natural language processing, or any algorithms or concepts. Therefore, there is no technical content on the slide to explain.","16
Why study Large Language Models
‚ñ™Reason 1: Capability"
1-introduction.pdf,16,"The slide contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content on the slide to explain.","17
Why study Large Language Models
‚ñ™Reason 2: In-context Learning
Input: Where is Stanford University?
Output: Stanford University is in California.
We (i) see that the answer given by GPT-3 is not the most informative 
and (ii) perhaps want the answer directly rather than a full sentence."
1-introduction.pdf,17,"The text on the slide identifies the institution, specifically the ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning, natural language processing, or any algorithms, equations, or architectures presented here.","18
Why study Large Language Models
‚ñ™Reason 2: In-context Learning
Similar to word analogies from earlier, we can construct a prompt that 
includes examples of what input/outputs look like. LLM manages to understand the 
task better from these examples and is now able to produce the desired answer.
Input: Where is MIT?
Output: Cambridge
Input: Where is University of Washington?
Output: Seattle
Input: Where is Stanford University?
Output: California"
1-introduction.pdf,18,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not provide any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain from this slide.","19
Why Large Language Models
‚ñ™Reason 3: Emergent properties in LLM
An ability not present in smaller models but present in larger models."
1-introduction.pdf,19,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is an institutional name and does not contain any technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no technical content to explain on this slide.","20
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Truthfulness, the answer seems correct but actually not"
1-introduction.pdf,20,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain.","21
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Social Bias"
1-introduction.pdf,21,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships presented on this slide.","22
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Toxicity. Large language models are trained on a huge amount of 
Internet data (e.g., Reddit), which inevitably contains offensive content.
Security and Privacy. Large language models can memorize, leak, or 
be manipulated into revealing sensitive data from training or user 
interactions."
1-introduction.pdf,22,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing presented on this slide. Therefore, there is no technical content to explain.","23
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Incapability in Knowledge Reasoning"
1-introduction.pdf,23,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only shows an institutional name without any technical information to explain.","24
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Incapability in Knowledge Reasoning
Correct Answer: Object A
Spatial 
Relation
Knowledge 
about a 
physical 
form"
1-introduction.pdf,24,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to ML or NLP concepts, algorithms, equations, or architectures. Therefore, there are no technical concepts to explain from this slide.","25
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Incapability in Long-Context Understanding"
1-introduction.pdf,25,"The slide contains only a textual header indicating the affiliated institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP presented on this slide.","26
Why Large Language Models
‚ñ™Reason 4: LLM do exist lots of limitations
Incapability in Creativity and Scientific Discovery
LLM only capture past human experiences"
1-introduction.pdf,26,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing, such as concepts, algorithms, equations, or architectures. Therefore, there is no technical content to describe from this slide.","27
Questions about LLM
‚ñ™What capabilities does LLM have?
‚ñ™Why are they so powerful?
‚ñ™How are they trained?
‚ñ™How should we use and adapt LLM?
‚ñ™How to address LLM limitations and mitigate their issues?
We will demystify these questions"
1-introduction.pdf,27,"The slide contains no technical content related to ML/NLP concepts, algorithms, equations, architectures, or relationships. It only displays the name of an academic institution, ""University of Florida Herbert Wertheim College of Engineering.""","28
What are we going to cover in the class?"
1-introduction.pdf,28,"The slide contains only the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, algorithms, equations, or architectures. Therefore, there is no relevant technical information to explain from this slide.","29
Part 1: Basic about Language Models
‚ñ™neural language modeling, dense word embeddings, tokenization, 
classical small language models"
1-introduction.pdf,29,"The slide contains only a text line with the name of a university and engineering college: ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content, concepts, algorithms, equations, architectures, or relationships related to ML/NLP or other topics. Therefore, there is no technical content on the slide to explain.","30
Part 2: Foundations in LLM
‚ñ™Model Architectures of LLM
‚ñ™Training and Inference of LLM"
1-introduction.pdf,30,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related concepts. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","31
Part 3: How to use and adapt LLM
‚ñ™Fine-tuning LLM and Post-training LLM
‚ñ™Advanced Post-training ‚Äì RL methods in LLM"
1-introduction.pdf,31,"The slide only contains a text header identifying the institution as ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no technical content to explain.","32
Part 4: Recent Advances in LLM
‚ñ™Advanced Topics: retrieval, knowledge, reasoning, agent, multi-modal 
‚ñ™LLM limitations and mitigation: harm, bias, toxification, hallucination"
1-introduction.pdf,32,"The slide contains no technical content related to machine learning or natural language processing. It only shows the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which likely serves as an institutional header or title. There are no concepts, algorithms, equations, or architectures presented on this slide.","33
Grading Components
Part i. Quizzes (25%): There will be 6 quizzes in class. Each quiz will 
take 10 minutes in class time. The format will be multi-choice question 
answering. The quiz will be closed book. The quiz will evaluate the 
knowledge learned in classes. Tentative quiz dates are Sep 5, Sep 19, 
Oct 3, Oct 24, Nov 7, Nov 21.
Part ii. Mid-term Exam (35%): The mid-term exam will be held on Oct 
10th 2025 in class (11:45am ‚Äì 12:35am at CSE E222). The exam will 
evaluate the knowledge covered in lectures before Oct 10. The exam 
will be closed book. No electricity device is allowed."
1-introduction.pdf,33,"The slide contains only a header text indicating the ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML content presented on this slide to explain.","34
Grading Components
Part iii. Final Project (40%): Four students will form a team, and will 
need to complete a final project. Here are components of submissions:
(1) Project Proposal (10%, due Oct 5): The proposal should include 
problem statement and objective, proposed methods, planned 
experiments, plan for contributions of each team member"
1-introduction.pdf,34,"This slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not have any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain here.","35
Grading Components
(2) In-class Presentation (15%): Each team will have 10-12 minutes for 
presentation and 3-5 minutes for Q&A. 
‚ñ™The presentation should include problem description, methods, 
experiments, result analysis, and conclusions. 
‚ñ™Each team should also prepare one quiz-like question (multi-choice 
format), that carries the most important takeaway message of the 
project (can be your core finding).
‚ñ™In-class presentation dates: Nov 7, 10, 12, 14, 17, 19, 21 (quiz)
‚ñ™Enter the team members and presentation date (max 3 teams per 
date) on google sheet (will be shared after add/drop deadline)"
1-introduction.pdf,35,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or NLP concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical details to explain from this slide.","36
Grading Components
(3) Final Report (15%, due Dec 5): The final report should be a formal 
paper-like report of the project, and should be concise and at most 9 
pages (NeurIPS template 
https://www.overleaf.com/latex/templates/neurips-2024/tpsbbrdqcmsh). 
‚ñ™The final report should include abstraction, introduction, related work, 
method description, dataset processing, experiment settings, 
experiment results, result analysis, and conclusion.
‚ñ™The report should also explain the contributions of each team member 
in the last section. 
‚ñ™The report can add additional experiments after presentation but should 
clearly state which part is added additionally."
1-introduction.pdf,36,"The slide only displays the text ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content such as machine learning or natural language processing concepts, algorithms, or equations to describe.","37
How to choose Final Project?
Here are three choices for final projects:
‚ñ™(1) choose the default project: fine-tuning LLMs for sentiment analysis
If you have limited experience with research, don‚Äôt have any clear idea of 
what you want to do, you can choose the default project, but you are 
expected to try to extend and improve it in various ways of your 
choice, like contrastive learning, paraphrasing, regularized optimization 
etc.
You need to find sentiment analysis datasets, there are many available 
online, such as rotten tomatoes, yelp ‚Ä¶"
1-introduction.pdf,37,"The slide contains only the name ""University of Florida Herbert Wertheim College of Engineering."" 

There is no technical content related to machine learning, natural language processing, or other related concepts, algorithms, equations, architectures, or relationships on this slide.","38
How to choose Final Project?
Here are three choices for final projects:
‚ñ™(2) reproducing a paper related to Natural Language Processing and 
Large Language Models (https://aclanthology.org/ provides paper 
database)
Should clearly state the previous codebase and highlight your 
contribution in presentation and final report. Only running the existing 
code will not get a good score. You are encouraged to extend and 
improve the original paper, like improvements to the model, providing 
ablations or experimental studies that the original paper did not provide, 
or by running it on different datasets that illuminate novel questions etc."
1-introduction.pdf,38,"The slide contains only the name of the institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or architectures related to ML/NLP presented on this slide to explain.","39
How to choose Final Project?
Here are three choices for final projects:
‚ñ™(3) any custom topics, potential topics can be LLMs reasoning, LLMs 
retrieval augmentation generation, LLMs hallucination detection or 
mitigation, LLMs for code generation, LLMs agent or multi-agent 
systems, LLMs for text summarization, LLMs for machine translation‚Ä¶
You are encouraged to choose custom project to explore the process of 
defining a problem, finding dataset, working out something you find 
interesting, and evaluating the system.
Again, you should clearly state the papers you cited and highlight the 
difference or contribution you made here."
1-introduction.pdf,39,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain.","40
Note about Final Project
‚ñ™The project topics should be human-language related, or text-related 
tasks, or multi-modality (including text-modality) tasks
‚ñ™A successful custom final project may develop a novel method or 
algorithm, but studying existing methods or applying them to new 
problems can also lead to interesting results without inventing 
something new.
‚ñ™A successful custom final project may improve on some existing SOTA, 
but well-executed projects that perform thoughtful experiments and 
produce negative results, projects that just aim to build a fun system, or 
projects that answer an interesting research question without advancing 
SOTA are equally valuable."
1-introduction.pdf,40,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" with no technical content related to machine learning or natural language processing concepts, algorithms, architectures, equations, or relationships. Therefore, there are no technical details to explain from this slide.","41
Note about Final Project (continued)
‚ñ™A successful final project should have clearly-defined evaluation 
metrics to measure the outcome of whatever experiment(s) you run; 
exact-match accuracy, precision, recall, and F1 score on either in-
distribution or out-of-distribution test data are used to evaluate 
experiments in the default final project.
‚ñ™A successful final project is encouraged to have a short, specific guiding 
question or hypothesis. An example of good guiding questions ‚ÄòDoes 
fine-tuning some BERT layers work better than others, and is the best 
layer to fine-tune the same for all tasks?‚Äô or ‚ÄòDoes pre-training in one 
language still help if we fine-tune on a different language?‚Äô"
1-introduction.pdf,41,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""","42
Note about Final Project (continued)
‚ñ™The models used for experiments are not restricted to language models 
with very large size. We do allow small or medium size language 
models for experiments. The key point is not the model size you use 
for experiments, but the research questions you find is valuable, the 
experiment design is reasonable and solid, your analysis is thoughtful, 
the evaluation is comprehensive.
‚ñ™Students are expected to not rely solely on calling LLMs API for their 
experiments. Prompting LLMs is allowed, but you should also at least 
train or fine-tune language model (even small language models) to 
compare results.
‚ñ™Every team is encouraged to submit a paper to ACL (discuss with me)"
1-introduction.pdf,42,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It simply displays the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional or organizational name and not a technical topic.","43
Resources for Final Project
‚ñ™HiPerGator provides GPUs for this course, 8 GPU (L4 or B200), 32 CPU 
cores, and 2 Tb of Blue storage.
‚ñ™Important note from HiPerGator management: if you use GPU for 
data visualization or train small-scale language model, use L4 GPU. 
You can use B200 only if your model size exceeds the capacity of L4, 
and you should expect job delays if you call B200.
‚ñ™Important!! Save the date: Sept 5 11:45am in classroom, a tutorial for 
HiPerGator will be provided.
‚ñ™Questions about project design or topic selection -> ask instructor; 
Questions about GPU usage or code difficulties: ask TA"
1-introduction.pdf,43,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, models, or mathematical expressions. It only displays the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical explanations, formulas, architectures, or terminology to analyze or describe.","44
Grading Scale
‚ñ™A = [92, 100] 
‚ñ™A ‚Äì = [89, 91.99] 
‚ñ™B + = [86, 88.99] 
‚ñ™B = [82, 85.99] 
‚ñ™B ‚Äì = [79, 81.99] 
‚ñ™C + = [76, 78.99] 
‚ñ™C = [72, 75.99] 
‚ñ™C ‚Äì = [69, 71.99] 
‚ñ™D + = [66, 68.99] 
‚ñ™D = [62, 65.99] 
‚ñ™D ‚Äì = [59, 61.99] 
‚ñ™E = [0, 58,99]"
1-introduction.pdf,44,"There is no technical content on this slide to explain. It only contains the text ""University of Florida Herbert Wertheim College of Engineering,"" which indicates an institution name and not any machine learning or NLP concepts, algorithms, or technical material.","45
Late Policies
For the submissions with due date, 25% is deducted for each late 24 
hours (including weekends). For example, if the submission is due on 
Sunday at 11:59pm, then 25% will be deducted for submission on 
Monday, 50% will be deducted for submission on Tuesday, 75% will be 
deducted for submissions on Wednesday, and submissions will not be 
accepted after Wednesday 11:59pm."
1-introduction.pdf,45,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only displays a textual header indicating the ""University of Florida Herbert Wertheim College of Engineering.""","46
Excused Absence 
The Dean of Students Office (www.dso.ufl.edu) provides rules, guidance, 
and approval for excuse documentation. An instructor notification letter 
from the DSO must directly state that an ‚Äúabsence has been excused‚Äù 
and the letter must specify the dates of the entire duration of the 
assessment. If the letter does not meet these requirements, the student 
must provide the instructor with documentation that complies with UF‚Äôs 
official excused absence policy (https://catalog.ufl.edu/UGRD/academic-
regulations/attendance-policies/#absencestext). Without this, the absence 
will not be considered excused, and accommodations cannot be 
provided."
1-introduction.pdf,46,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or other NLP/ML content presented on the slide to describe.","47
Academic Integrity 
UF students are bound by The Honor Pledge which states, ‚ÄúWe, the 
members of the University of Florida community, pledge to hold ourselves 
and our peers to the highest standards of honor and integrity by abiding 
by the Honor Code 
https://policy.ufl.edu/regulation/4-040/
https://sccr.dso.ufl.edu/process/student-conduct-code/"
1-introduction.pdf,47,There is no technical content visible on this slide to explain.,Thank you!
10-generation.pdf,0,"The slide contains no visible technical content such as concepts, algorithms, equations, architectures, or relationships relevant to ML or NLP for explanation.","CIS 6930 Special Topics in Large Language Models
LLM Generation (Inference)"
10-generation.pdf,1,"The slide does not contain any technical content related to machine learning or natural language processing. It displays the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation rather than a technical concept, algorithm, or model.","2
Outline
‚ñ™Introduction to LLM Generation
‚ñ™Decoding Algorithms for LLM Generation
‚ñ™Training Generation Models
‚ñ™Evaluating LLM Generation
‚ñ™Ethical Considerations"
10-generation.pdf,2,"This slide only contains the name of the institution: ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning or natural language processing such as concepts, algorithms, equations, or architectures.","3
Introduction to LLM Generation"
10-generation.pdf,3,"The slide contains only textual information that identifies an institution: ""University of Florida Herbert Wertheim College of Engineering.""

There is no technical content such as concepts, algorithms, equations, or architectures related to Machine Learning or NLP present on this slide.","4
LLM Generation Use Case"
10-generation.pdf,4,"The slide contains only a text header displaying the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning, natural language processing, or other related topics on this slide.","5
More Interesting LLM Generation"
10-generation.pdf,5,"The slide content does not contain any technical concepts, algorithms, architectures, or equations related to machine learning or natural language processing. It only displays the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering.""","6
Training via Teacher Forcing"
10-generation.pdf,6,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning, NLP, algorithms, concepts, or architectures.

Please provide a slide with technical material for explanation.","7
Inference via Student Forcing"
10-generation.pdf,7,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an educational institution ‚Äî ""University of Florida Herbert Wertheim College of Engineering.""","8
Decoding Algorithm during Inference"
10-generation.pdf,8,"The slide only contains the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide for explanation.","9
Decoding Algorithms for LLM Generation"
10-generation.pdf,9,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is the name of an educational institution. Please provide a slide with technical material for explanation.","10
Decoding Algorithms
‚ñ™Greedy Search Decoding
‚ñ™Beam Search Decoding
‚ñ™Top-K Sampling Decoding
‚ñ™Top-P Sampling Decoding
‚ñ™More about Decoding ‚Äì Repetition, Temperature, Re-Ranking"
10-generation.pdf,10,"The slide contains only the title: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning, NLP concepts, algorithms, equations, architectures, or relationships. Hence, there is no technical material to explain from this slide.","11
Greedy Decoding"
10-generation.pdf,11,"The slide contains only the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is not related to any technical content in machine learning or natural language processing. There are no concepts, algorithms, equations, architectures, or technical relationships presented on this slide to explain.","12
Problems with Greedy Decoding"
10-generation.pdf,12,"The slide contains only a textual heading ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning, natural language processing, or related algorithms. Therefore, there is no technical material to explain from this slide.","13
Exhaustive Search Decoding"
10-generation.pdf,13,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing such as concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","14
Beam Search Decoding"
10-generation.pdf,14,"The slide contains only an institutional header stating ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning, natural language processing, or related concepts. Therefore, no technical concepts, algorithms, or architectures can be explained based on this slide.","15
Beam Search Decoding ‚Äì Example"
10-generation.pdf,15,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical concepts to explain from this slide.","16
Beam Search Decoding ‚Äì Example"
10-generation.pdf,16,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There is no technical content related to machine learning, NLP, or other relevant subjects on this slide to explain.","17
Beam Search Decoding ‚Äì Example"
10-generation.pdf,17,"The slide does not contain technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only mentions the ""University of Florida Herbert Wertheim College of Engineering."" Please provide a slide with specific technical material for explanation.","18
Beam Search Decoding ‚Äì Example"
10-generation.pdf,18,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related concepts. There are no algorithms, equations, architectures, or relationships described on this slide to explain.","19
Beam Search Decoding ‚Äì Example"
10-generation.pdf,19,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It is simply a text header indicating ""University of Florida Herbert Wertheim College of Engineering."" There are no technical terms or topics to explain.","20
Beam Search Decoding ‚Äì Example"
10-generation.pdf,20,"The slide content you provided contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical concepts, algorithms, equations, or related NLP/ML content. Please provide a slide with relevant technical content for me to describe.","21
Beam Search Decoding ‚Äì Example"
10-generation.pdf,21,"There is no technical content such as concepts, algorithms, equations, or architectures on this slide. It only contains a header with the text: ""University of Florida Herbert Wertheim College of Engineering.""","22
Beam Search Decoding ‚Äì Example"
10-generation.pdf,22,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is an institutional affiliation. There is no technical content, concept, algorithm, equation, or architecture related to Machine Learning or Natural Language Processing present on this slide to explain.","23
Beam Search Decoding ‚Äì Example"
10-generation.pdf,23,"The slide does not contain any technical content related to machine learning or NLP concepts, algorithms, equations, or architectures. It only displays the name of the institution: ""University of Florida Herbert Wertheim College of Engineering."" Please provide a slide with technical content to explain.","24
Beam Search Decoding ‚Äì Example"
10-generation.pdf,24,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is identifying an institution rather than presenting any technical content related to machine learning or natural language processing. There are no concepts, algorithms, equations, or architectures shown on this slide to describe.","25
Beam Search Decoding ‚Äì Example"
10-generation.pdf,25,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only shows the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation or heading, not a technical explanation.","26
Beam Search Decoding ‚Äì Example"
10-generation.pdf,26,"The slide contains only a textual header: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.","27
Beam Search Decoding ‚Äì Example"
10-generation.pdf,27,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of a university college and therefore does not require or provide any explanation of ML/NLP concepts, algorithms, equations, or architectures.","28
Beam Search Decoding ‚Äì Stopping Criterion"
10-generation.pdf,28,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain.","29
Beam Search Decoding ‚Äì Finishing Up"
10-generation.pdf,29,"The content on the slide is limited to the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or NLP/ML content presented on this slide to explain.","30
Problems of failing to match uncertainty"
10-generation.pdf,30,"The text on the slide simply states the affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP to explain here.","31
How to solve ‚Äì Sampling"
10-generation.pdf,31,"The slide contains no technical content related to machine learning or natural language processing. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be a heading or institutional title. No algorithms, models, concepts, or equations are presented on this slide.","32
Top-K Sampling Decoding"
10-generation.pdf,32,"The slide contains only the title ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there is no technical material to explain from this slide.","33
Top-K Sampling Decoding"
10-generation.pdf,33,"The slide appears to show only institutional or departmental information (""University of Florida Herbert Wertheim College of Engineering"") and contains no technical content related to machine learning or natural language processing. Please provide a slide with technical concepts so I can explain the relevant algorithms or models.","34
Problems of Top-K Sampling Decoding"
10-generation.pdf,34,"The slide only shows the name ""University of Florida Herbert Wertheim College of Engineering"" and contains no technical content related to machine learning, NLP, or any associated concepts, algorithms, or architectures. There are no equations or relationships presented here.","35
Top-P (nucleus) Sampling Decoding"
10-generation.pdf,35,"The slide contains only a text header indicating the institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or architectural descriptions related to Machine Learning or Natural Language Processing presented on this slide.","36
Top-P (nucleus) Sampling Decoding"
10-generation.pdf,36,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related topics. Therefore, there are no technical concepts, algorithms, or equations to explain from this slide.","37
More about Decoding ‚Äì Problems of Repetitive"
10-generation.pdf,37,"The slide contains only the title ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content related to machine learning, natural language processing, or any specific algorithms, architectures, or concepts to explain.","38
Why does repetitive happen?"
10-generation.pdf,38,"The slide only contains a text header: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML content present to describe.","39
Why does repetitive happen?"
10-generation.pdf,39,"The slide simply states ""University of Florida Herbert Wertheim College of Engineering"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. There are no equations or relationships to explain in the given text.","40
How do we reduce repetition"
10-generation.pdf,40,"The slide does not contain any technical content related to machine learning or natural language processing. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name and not a concept, algorithm, or technical element.","41
More about Decoding ‚Äì Temperature"
10-generation.pdf,41,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. Therefore, there is no technical content to explain.","42
More about Decoding ‚Äì Reranking"
10-generation.pdf,42,"The slide contains only the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any technical content related to machine learning, natural language processing, or any associated concepts, algorithms, or architectures. There are no technical terms, equations, or concepts to explain in this slide.","43
Recap
‚ñ™Greedy Search Decoding
‚ñ™Beam Search Decoding
‚ñ™Top-K Sampling Decoding
‚ñ™Top-P Sampling Decoding
‚ñ™More about Decoding ‚Äì Repetition, Temperature, Re-Ranking"
10-generation.pdf,43,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to ML or NLP concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain from this slide.","44
Training Generation Models"
10-generation.pdf,44,"The slide contains no technical content related to machine learning or natural language processing. It only includes the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which indicates an institutional affiliation, not a technical concept or algorithm.","45
Problem of Exposure Bias"
10-generation.pdf,45,"The slide contains no technical content related to machine learning or natural language processing. It only shows an institutional affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships presented on this slide.","46
Solving Exposure Bias during Training"
10-generation.pdf,46,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only shows the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering."" Therefore, there is no relevant technical explanation to provide from this slide.","47
Solving Exposure Bias during Training"
10-generation.pdf,47,"The slide contains no technical content related to machine learning, natural language processing, or other related concepts. It only displays the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation, not technical material for an ML/NLP course.","48
Solving Exposure Bias ‚Äì Reward Design in RL"
10-generation.pdf,48,"The slide does not contain any technical content related to machine learning, natural language processing, or relevant algorithms or concepts. It only displays the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name and does not convey any ML/NLP concepts or technical information.","49
Recap
‚ñ™Problem of Exposure Bias
(Mismatch between training and inference)
‚ñ™Solution for Exposure Bias
(Schedule Sampling, Dataset Aggregation, Sequence Rewriting, RL)"
10-generation.pdf,49,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, algorithms, equations, or architectures. Therefore, there are no technical concepts or relationships to explain from this slide.","50
Evaluating LLM Generation"
10-generation.pdf,50,"The slide does not contain any technical content related to machine learning or natural language processing. It only contains a text header indicating an institutional name: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, models, or technical details to explain.","51
Types of Evaluation Methods for LLM Generation"
10-generation.pdf,51,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional label or heading. There is no technical content related to machine learning, natural language processing, or any algorithms, concepts, or architectures present on this slide.","52
Content Overlap Metrics (n-gram overlap)"
10-generation.pdf,52,"The slide shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" However, it does not contain any technical content related to machine learning, natural language processing, or related algorithms, models, or equations. Please provide a slide with specific technical content for explanation.","53
Content Overlap Metrics (n-gram overlap)"
10-generation.pdf,53,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is an institutional or organizational title. There are no technical concepts, algorithms, equations, architectures, or NLP/ML content on this slide to explain.","54
Limitation of n-gram overlap metric"
10-generation.pdf,54,"The slide only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP present on the slide to explain.","55
Model-based Metric to capture more semantics"
10-generation.pdf,55,"The slide contains only a text line with the name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP presented here.","56
Model-based Metric"
10-generation.pdf,56,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is an institutional name and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.","57
Model-based Metric"
10-generation.pdf,57,"The slide only contains a text line specifying ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, or architectures presented on this slide related to machine learning or natural language processing to explain.","58
Automatic Evaluation Metric doesn‚Äôt always work"
10-generation.pdf,58,"The slide contains only the textual content ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","59
Human Evaluation"
10-generation.pdf,59,"The slide contains only the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, or architectures described on this slide.","60
Human Evaluation"
10-generation.pdf,60,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering,"" which appears to be an institutional or affiliation header. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","61
Human Evaluation ‚Äì Issues"
10-generation.pdf,61,"The slide contains only the name of an academic institution, specifically the ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML-related content presented here for explanation.","62
Recap
‚ñ™Content Overlap Metric (n-gram overlap)
Provide a good starting point for evaluating the quality of generated text. 
But cannot capture semantics similarity
‚ñ™Model-based Metric
Can capture semantic-level similarity, more correlated with human eval. 
But behavior is not interpretable, and not always align with human
‚ñ™Human Evaluation
Necessary for evaluating quality of generated text. But is slow and hard."
10-generation.pdf,62,"The slide contains only the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, or architectural details related to machine learning or natural language processing presented on this slide.","63
Ethical Considerations"
10-generation.pdf,63,"The slide contains no technical content related to ML, NLP, or related concepts. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be the name of an educational institution and does not convey any technical material to explain.","64
ChatGPT is filtered to not generated toxic content"
10-generation.pdf,64,"The slide contains only the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content, concepts, algorithms, equations, or architectures related to ML or NLP.","65
Jailbreaking
But there are still problems
Like Jailbreaking"
10-generation.pdf,65,"The slide only contains the heading ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning, natural language processing, or related algorithms and architectures. Therefore, there are no technical concepts, models, or equations on this slide to describe.","66
Factual Errors"
10-generation.pdf,66,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or their relationships. Therefore, there are no technical concepts to explain from this slide.","67
Social Bias"
10-generation.pdf,67,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is an institutional or organizational name. There are no technical concepts, algorithms, equations, architectures, or relationships present on this slide to analyze or explain.","68
Adversarial Attacks"
10-generation.pdf,68,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name. It does not present any technical content related to machine learning, natural language processing, models, algorithms, or related concepts. Therefore, there is no technical material to explain from this slide.","69
Ethical Considerations"
10-generation.pdf,69,"The slide contains no technical content related to ML/NLP concepts, algorithms, equations, architectures, or relationships. It appears to be an image of a building with some tagline text, but there are no details relevant to machine learning or natural language processing technical topics.",Thank you!
11-post-training.pdf,0,"The slide does not contain any visible technical content related to ML or NLP concepts, algorithms, equations, architectures, or relationships. It appears to be an image of a building and a tagline ""Leading the Charge, Charging Ahead,"" but it has no explicit technical details to describe.","CIS 6930 Special Topics in Large Language Models
LLM Post-Training"
11-post-training.pdf,1,"The slide only contains a text header indicating the institution name, which is ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, or other related concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain from this slide.","2
Larger and Larger Models"
11-post-training.pdf,2,"The slide contains only a text header indicating ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there are no technical concepts, algorithms, equations, architectures, or relationships to explain from this slide.","3
More and More Data"
11-post-training.pdf,3,"The slide contains only the name ""University of Florida Herbert Wertheim College of Engineering"" and no technical content related to machine learning or natural language processing. There are no concepts, algorithms, equations, architectures, or relationships to explain.","4
What does LLM learn?"
11-post-training.pdf,4,"This slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content such as concepts, algorithms, equations, or architectures related to machine learning or NLP present on the slide to explain.","5
LLM as Multi-task Helper?
Math
Code
Medicine"
11-post-training.pdf,5,"The slide contains only a textual header indicating the institution name: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. Therefore, there is no technical content to describe.","6
What happens after LLM pre-training?"
11-post-training.pdf,6,"The slide only contains a textual header: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or NLP/ML content presented on this slide to explain.","7
Outline
‚ñ™Zero-shot and Few-shot in In-context Learning
‚ñ™Instruction Tuning
‚ñ™Optimization for Human Preference
1. Reinforcement Learning from Human Feedback (RLHF)
2. Direct Preference Optimization (DPO)"
11-post-training.pdf,7,"The slide presents the name of the educational institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not contain any technical content related to machine learning, natural language processing, or related algorithms. Therefore, there are no technical concepts, equations, architectures, or relationships to explain from this slide.","8
In-Context Learning"
11-post-training.pdf,8,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not show any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to describe from this slide.","9
Emergent Capability of LLM"
11-post-training.pdf,9,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is not related to technical content in machine learning or natural language processing. There are no concepts, algorithms, architectures, or equations presented here to explain.","10
Emergent Zero-Shot Learning"
11-post-training.pdf,10,"The slide contains only a header with the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"". There is no technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","11
Emergent Zero-Shot Learning"
11-post-training.pdf,11,"The slide contains no technical content related to machine learning or natural language processing. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be an institutional or affiliation header. There are no concepts, algorithms, models, or equations presented on this slide.","12
Emergent Zero-Shot Learning"
11-post-training.pdf,12,"The slide contains only a single line of text specifying the institution name: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing present on this slide.","13
Emergent Few-Shot Learning"
11-post-training.pdf,13,"The slide only contains a text indicating the institution name: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML content presented on this slide to describe.","14
Emergent Few-Shot Learning"
11-post-training.pdf,14,"The text on the slide simply indicates the name of an academic institution, specifically the ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning, natural language processing, or other related concepts, algorithms, equations, or architectures. Therefore, there is no relevant technical content to explain from this slide.","15
Emergent Few-Shot Learning"
11-post-training.pdf,15,"The slide text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only specifies the institution and college name.","16
Emergent Few-Shot Learning"
11-post-training.pdf,16,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there are no technical concepts, algorithms, architectures, or equations to explain from this slide.","17
New Methods of Prompting LM"
11-post-training.pdf,17,"The slide content is limited to a textual header stating ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical details to explain from this slide.","18
Limits of Prompting for harder tasks"
11-post-training.pdf,18,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only states the name ""University of Florida Herbert Wertheim College of Engineering.""","19
Chain-of-Thought Prompting"
11-post-training.pdf,19,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation and does not include any concepts, algorithms, equations, or architectures.","20
Chain-of-Thought Prompting
Chain-of-Thought prompting is an emergent property of model scale"
11-post-training.pdf,20,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which refers to an academic institution. There is no technical content such as concepts, algorithms, equations, or architectures related to machine learning or natural language processing on this slide to explain.","21
Chain-of-Thought Prompting"
11-post-training.pdf,21,"There is no technical content related to machine learning or natural language processing on this slide. It contains only the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""","22
Zero-shot Chain-of-Thought Prompting"
11-post-training.pdf,22,"The slide contains only the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. There are no technical elements to explain on this slide.","23
Zero-shot Chain-of-Thought Prompting"
11-post-training.pdf,23,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical concepts on this slide to explain.","24
Zero-shot Chain-of-Thought Prompting"
11-post-training.pdf,24,"The text on this slide reads ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing presented on this slide.","25
Recap
Zero-shot and Few-shot in In-context Learning
‚ñ™Pro: 
No finetuning needed, prompt engineering (e.g. CoT) is helpful
‚ñ™Cons: 
Limits to what you can fit in context
Complex tasks will probably need gradient steps"
11-post-training.pdf,25,"The slide contains only a textual header: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and no technical content related to machine learning, natural language processing, or other concepts. There are no algorithms, equations, architectures, or relationships described on this slide.","26
Instruction Tuning"
11-post-training.pdf,26,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It simply displays the name ""University of Florida Herbert Wertheim College of Engineering,"" which appears to represent an institutional affiliation rather than a technical topic.","27
LM may not align with user intent"
11-post-training.pdf,27,"This slide presents the institutional affiliation, ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning or natural language processing concepts, algorithms, or architectures.","28
LM may not align with user intent"
11-post-training.pdf,28,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional title and does not contain technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from a technical ML/NLP perspective on this slide.","29
Recall Pretraining / Finetuning paradigm"
11-post-training.pdf,29,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain.","30
Scaling up Finetuning with Instructions"
11-post-training.pdf,30,"The slide contains only a heading indicating the institution name: ""University of Florida Herbert Wertheim College of Engineering."" It does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical concepts to explain from this slide.","31
Instruction Tuning"
11-post-training.pdf,31,"The slide only contains the phrase ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, algorithms, models, or equations. There are no concepts or relationships to explain here.","32
Instruction Tuning
For example, Super-
Natural Instructions 
dataset contains over 1.6K 
tasks, 3M+ examples
Tasks include classification, 
sequence tagging, rewriting, 
translation, QA..."
11-post-training.pdf,32,"The slide heading indicates affiliation with the University of Florida Herbert Wertheim College of Engineering, which suggests the technical content following would relate to engineering disciplines such as machine learning (ML) or natural language processing (NLP). However, there are no technical concepts, algorithms, equations, architectures, or relationships presented on this slide. It appears to be a title or header slide with institutional identification only.

Thus, no technical content is shown to explain on this slide.","33
Evaluate LLM after Instruction Tuning"
11-post-training.pdf,33,"There is no technical content on this slide. It contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which likely represents the institution or department affiliated with the presentation.","34
Evaluate LLM after Instruction Tuning"
11-post-training.pdf,34,"The text on the slide indicates the institution name ""University of Florida Herbert Wertheim College of Engineering"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.","35
Evaluate LLM after Instruction Tuning
impressive progress on challenging knowledge-intensive benchmarks
Progress on MMLU"
11-post-training.pdf,35,"The slide content consists solely of the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical material related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","36
Instruction Tuning
T5 pretrained on span 
corruption task
Flan-T5: instruction tuning 
T5 models on 1.8k additional 
tasks"
11-post-training.pdf,36,"The slide contains no technical content related to machine learning or natural language processing. It simply displays the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures presented.","37
Instruction Tuning"
11-post-training.pdf,37,"The slide contains only a header text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. There are no technical explanations, equations, or diagrams present on the slide to describe.","38
Instruction Tuning"
11-post-training.pdf,38,"The text visible on the slide is ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML content presented to explain. If you have another slide with technical content, please share it so I can provide the explanation.","39
Limitations of Instruction Tuning
‚ñ™It‚Äôs expensive to collect ground truth data for tasks
‚ñ™Tasks like open-ended creative generation have no right answer
e.g. Write me a story about a dog and her pet grasshopper.
‚ñ™Humans generate suboptimal answers
‚ñ™Even with instruction finetuning, there a mismatch between the LM 
objective and the objective of ‚Äúsatisfying human preferences‚Äù"
11-post-training.pdf,39,"The text on this slide appears to be the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. If you have another slide with specific technical content, please share that for explanation.","40
Recap
Instruction Tuning
‚ñ™Pro: 
Simple and straightforward, generalize to unseen tasks
‚ñ™Cons: 
Collecting demonstrations for so many tasks is expensive
Mismatch between LM objective and human preferences"
11-post-training.pdf,40,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","41
Optimization for Human Preference"
11-post-training.pdf,41,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an academic institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures to explain.","42
Optimization for Human Preference"
11-post-training.pdf,42,"The slide contains only text indicating ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical details to explain from this slide.","43
RLHF (Reinforcement Learning from Human Feedback) 
Instruction Tuning
Reward Model
PPO (Proximal Policy Optimization)"
11-post-training.pdf,43,"The slide contains no technical content on machine learning or natural language processing concepts, algorithms, or architectures. It only shows an institutional name, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical details such as equations, models, or terms related to ML or NLP to explain.","44
RLHF ‚Äì Reward Model"
11-post-training.pdf,44,"The slide contains only a heading indicating affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide to explain.","45
RLHF ‚Äì Reward Model"
11-post-training.pdf,45,"The slide contains only the name of an academic institution, ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content such as concepts, algorithms, equations, or architectures related to ML or NLP to explain.","46
RLHF ‚Äì Reward Model"
11-post-training.pdf,46,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It simply displays the text ""University of Florida Herbert Wertheim College of Engineering,"" which appears to be an institutional or author affiliation header, with no relevant technical material to explain.","47
RLHF ‚Äì Reward Model"
11-post-training.pdf,47,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there is no technical material to explain from this slide.","48
RLHF ‚Äì Reward Model"
11-post-training.pdf,48,"The slide contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is a heading or title likely indicating the institutional affiliation or source of the presentation. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented in this slide.","49
RLHF ‚Äì Reward Model"
11-post-training.pdf,49,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning, natural language processing, or associated concepts. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","50
RLHF ‚Äì Proximal Policy Optimization (PPO)"
11-post-training.pdf,50,"The slide text indicates an institutional affiliation‚Äîspecifically, the University of Florida's Herbert Wertheim College of Engineering. However, this content does not contain any technical material related to machine learning, natural language processing, or related algorithms or concepts. Therefore, there are no technical concepts, equations, architectures, or relationships to explain from this slide.","51
RLHF ‚Äì Proximal Policy Optimization (PPO)"
11-post-training.pdf,51,"The text on the slide simply states an institutional affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented here. Thus, there is no technical content related to machine learning or natural language processing to explain from this slide.","52
RLHF ‚Äì Proximal Policy Optimization (PPO)"
11-post-training.pdf,52,"The slide contains only a single text line with the name of an institution and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.

Therefore, there are no technical concepts or explanations to describe from this slide.","53
RLHF
RLHF provides gains over pre-training + instruction fine-tuning"
11-post-training.pdf,53,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" with no technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations. Therefore, there is no technical material to explain from this slide.","54
RLHF ‚Äì clear stylistic changes"
11-post-training.pdf,54,"The slide contains the name of an academic institution, ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, or associated concepts, algorithms, or architectures. Therefore, there is no technical material to explain from this slide.","55
InstructGPT: scaling up RLHF to thousands of tasks"
11-post-training.pdf,55,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and thus does not present any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. There are no equations, models, or technical relationships displayed on this slide to explain.","56
InstructGPT"
11-post-training.pdf,56,"The slide header indicates the affiliation or institution‚ÄîUniversity of Florida Herbert Wertheim College of Engineering‚Äîbut contains no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there are no technical concepts to explain from this slide.","57
InstructGPT"
11-post-training.pdf,57,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related concepts. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","58
RLHF (Reinforcement Learning from Human Feedback) 
Instruction Tuning
Reward Model
PPO can be simplified to DPO"
11-post-training.pdf,58,"The slide does not present any technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures shown on the slide to explain.","59
RLHF ‚Äì Direct Preference Optimization (DPO)"
11-post-training.pdf,59,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not provide any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. There are no concepts such as n-gram language models, Markov assumptions, transformers, RNNs, decoding methods, perplexity metrics, or smoothing techniques mentioned on the slide.","60
RLHF ‚Äì Direct Preference Optimization (DPO)"
11-post-training.pdf,60,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","61
RLHF ‚Äì Direct Preference Optimization (DPO)"
11-post-training.pdf,61,"The slide contains only a text line specifying the name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical content, concepts, algorithms, equations, or architectures related to ML/NLP presented on this slide.","62
Summary of PPO and DPO"
11-post-training.pdf,62,"This slide only shows the name of an institution, ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.","63
Open source LLMs use DPO more"
11-post-training.pdf,63,"There is no technical content related to machine learning or natural language processing on this slide. It simply contains the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering."" Please provide a slide with technical content for explanation.","64
Limitations of RL + Reward Modeling"
11-post-training.pdf,64,"The slide contains purely textual information displaying the name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing to explain here.","65
Limitations of RL + Reward Modeling"
11-post-training.pdf,65,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or other NLP/ML-related content presented on this slide to describe.","66
Recap
Optimization for Human Preference (RLHF PPO / DPO)
‚ñ™Pro: 
Directly model preferences, generalize beyond labeled data
‚ñ™Cons: 
RL is very tricky to get right
Human preferences are unreliable
models of human preferences are even more unreliable"
11-post-training.pdf,66,"The slide contains no technical content related to ML/NLP concepts, algorithms, equations, architectures, or their relationships. It only shows an image of a building with the phrase ""LEADING THE CHARGE, CHARGING AHEAD"" at the bottom right. There are no technical concepts or details to explain.",Thank you!
12-reasoning.pdf,0,"The slide contains no visible textual or graphic technical content related to ML or NLP concepts, algorithms, equations, or architectures. It appears to be an image of a building exterior with the phrase ""LEADING THE CHARGE, CHARGING AHEAD"" at the bottom. There are no technical details to describe from an ML/NLP perspective.","CIS 6930 Special Topics in Large Language Models
LLM Reasoning"
12-reasoning.pdf,1,"The slide contains only the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no technical content to explain.","2
Outline
‚ñ™Introduction to LLM Reasoning
‚ñ™Methods for LLM Reasoning
1.
Chain-of-Thought Prompting / Decoding
2.
Least-to-Most
3.
Self-Consistency
4.
Self-Improve
5.
Analogical Prompting
6.
Step-back Abstraction Prompting
7.
Small LM Reasoning
‚ñ™Analysis of LLM Reasoning"
12-reasoning.pdf,2,"The slide only contains the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"".

There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP presented on this slide.","3
Introduction to LLM Reasoning"
12-reasoning.pdf,3,"The slide contains only a header text indicating the affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented on this slide.","4
What is Reasoning"
12-reasoning.pdf,4,"The slide itself contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. 

Please provide a slide with technical content or specify the topic you would like described.","5
Formal vs Informal Reasoning"
12-reasoning.pdf,5,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional or organizational name. There are no technical concepts, algorithms, architectures, equations, or NLP/ML content presented on this slide to explain.","6
LLM Reasoning
‚ñ™Large Language models are really good at predicting plausible 
continuations of text (text generation via language modeling), that 
respect constraints in the input (conditioned generation), and align 
well with human preferences (post-training lecture)
‚ñ™Question: Can current LLMs reason?"
12-reasoning.pdf,6,"The slide contains only a text header indicating an institution name ‚Äî it does not include any technical content related to machine learning, NLP concepts, algorithms, equations, or architectures to explain.","7
LLM Reasoning"
12-reasoning.pdf,7,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain based on this slide.","8
LLM Reasoning"
12-reasoning.pdf,8,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to ML or NLP concepts, algorithms, equations, architectures, or their relationships. Therefore, there is no technical content to explain for this slide.","9
Why ‚ÄúIntermediate Tokens‚Äù / ‚ÄúReasoning‚Äù Matters?"
12-reasoning.pdf,9,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional affiliation. There are no technical concepts, equations, models, or relationships to explain.","10
Chain-of-Thought"
12-reasoning.pdf,10,"The slide only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to ML or NLP concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","11
Chain-of-Thought Prompting"
12-reasoning.pdf,11,"The slide contains no technical content to explain. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name, not related to ML or NLP concepts, algorithms, or architectures.","12
Zero-shot Chain-of-Thought Prompting"
12-reasoning.pdf,12,"The text on the slide simply indicates the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation. There are no technical concepts, algorithms, equations, architectures, or relationships present on this slide to describe from an ML or NLP perspective.","13
Pros and Cons of Chain-of-Thought Prompting"
12-reasoning.pdf,13,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It simply displays the name of the institution: ""University of Florida Herbert Wertheim College of Engineering.""","14
Pros and Cons of Chain-of-Thought Prompting"
12-reasoning.pdf,14,"The slide only contains the name ""University of Florida Herbert Wertheim College of Engineering,"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there is no technical content to explain from this slide.","15
Chain-of-Thought Decoding"
12-reasoning.pdf,15,"There is no technical content such as concepts, algorithms, equations, or architectures on this slide. It only contains the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name.","16
Chain-of-Thought Decoding"
12-reasoning.pdf,16,"The slide contains only a text header indicating an institution name, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or architectures related to machine learning or NLP presented on this slide.","17
Chain-of-Thought Decoding"
12-reasoning.pdf,17,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It simply displays the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no ML/NLP topics presented on this slide to explain.","18
Chain-of-Thought Decoding"
12-reasoning.pdf,18,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or NLP concepts, algorithms, or models. There are no equations, architectures, or relationships to explain.","19
Chain-of-Thought Decoding"
12-reasoning.pdf,19,"The slide only contains the name of an institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not include any technical content related to machine learning, natural language processing, or related concepts. Therefore, there are no algorithms, equations, models, or technical relationships to describe from this slide.","20
Recap
Chain-of-Thought Methods:
‚ñ™Chain-of-Thought Prompting 
1. Chain-of-Thought Prompting ‚Äì reasoning process of few examples
2. Zero-shot Chain-of-Thought Prompting ‚Äì ‚Äúlet‚Äôs think step by step‚Äù
‚ñ™Chain-of-Thought Decoding
Sample multiple candidates and choose the one with the highest 
confidence on the final answer"
12-reasoning.pdf,20,"The slide contains only the name of an institution, ‚ÄúUniversity of Florida Herbert Wertheim College of Engineering,‚Äù and does not present any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there is no technical material to explain for this slide.","21
Least-to-Most Prompting"
12-reasoning.pdf,21,"The slide contains only the name of a university and its college of engineering. There are no technical concepts, algorithms, equations, or architectures described on this slide. Therefore, there is no relevant ML/NLP technical content to explain.","22
Problem decomposition with Least-to-Most Prompting"
12-reasoning.pdf,22,"The slide does not contain any technical content related to machine learning or natural language processing. It simply displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional affiliation. There are no concepts, algorithms, equations, architectures, or technical relationships presented on this slide.","23
Problem decomposition with Least-to-Most Prompting"
12-reasoning.pdf,23,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical details to explain based on this slide.","24
Problem decomposition with Least-to-Most Prompting"
12-reasoning.pdf,24,"The slide contains only the name ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning, natural language processing, algorithms, equations, or architectures. Therefore, there are no technical concepts or explanations to describe from this slide.","25
Self-Consistency"
12-reasoning.pdf,25,"The slide only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"". It does not contain any technical content related to Machine Learning, Natural Language Processing, or other concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain.","26
Self-Consistency"
12-reasoning.pdf,26,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. There is no relevant technical material to explain on this slide.","27
Self-Consistency"
12-reasoning.pdf,27,"The slide content contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships to explain.","28
Self-Consistency"
12-reasoning.pdf,28,"The slide does not contain any technical content related to machine learning or natural language processing. It only shows the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional header or affiliation. No concepts, algorithms, equations, architectures, or relationships related to ML/NLP are presented here.","29
Self-Consistency"
12-reasoning.pdf,29,"The slide contains only the name of the institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any technical content related to machine learning, natural language processing, or related algorithms, concepts, or equations.","30
Self-Consistency"
12-reasoning.pdf,30,"The slide contains only a text header ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" without any technical content related to ML or NLP concepts, algorithms, equations, architectures, or relationships. There is no technical material on this slide to explain.","31
Self-Consistency"
12-reasoning.pdf,31,"The slide contains only the name of the institution ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content, concepts, algorithms, or equations related to ML/NLP. Therefore, there is no technical content on this slide to explain.","32
Self-Consistency"
12-reasoning.pdf,32,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","33
Self-Improve"
12-reasoning.pdf,33,"This slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or other relevant concepts, algorithms, or architectures. There are no equations, models, or related material to explain for this slide.","34
Motivation comes from SFT"
12-reasoning.pdf,34,"The slide contains only the name of the institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations. There is no technical material to explain from this slide.","35
Motivation comes from SFT"
12-reasoning.pdf,35,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only displays the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering.""","36
Motivation comes from SFT"
12-reasoning.pdf,36,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, NLP, or other relevant concepts, algorithms, equations, or architectures. Therefore, there is no technical content to explain based on this slide.","37
Motivation comes from SFT"
12-reasoning.pdf,37,"The slide contains only the name of an academic institution ‚Äî ""University of Florida Herbert Wertheim College of Engineering."" It does not present any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing to describe.","38
Self-Improve"
12-reasoning.pdf,38,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning, natural language processing, or related concepts. Please provide a slide with technical content for explanation.","39
Self-Improve"
12-reasoning.pdf,39,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be the name of an institution.","40
Self-Improve"
12-reasoning.pdf,40,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name and does not include any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP. Therefore, there is no technical content on this slide to explain.","41
Self-Improve"
12-reasoning.pdf,41,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain.","42
Scaling Reasoning Training: What to Scale?"
12-reasoning.pdf,42,"The slide includes only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or their relationships. Therefore, there are no technical details to explain from this slide.","43
Analogical Prompting"
12-reasoning.pdf,43,"The slide content does not contain any technical information related to machine learning or natural language processing. It only displays a text string: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"", which appears to be an institutional or departmental name. There are no concepts, algorithms, equations, architectures, or other technical details presented on this slide for explanation.","44
Analogical Prompting"
12-reasoning.pdf,44,"The content on the slide does not contain any technical material related to machine learning or natural language processing. It simply displays the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no concepts, algorithms, equations, or architectures presented to explain.","45
Step-Back Abstraction Prompting"
12-reasoning.pdf,45,"The slide shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional identification or branding. There are no technical concepts, algorithms, equations, or architectural details related to machine learning or NLP presented on this slide. Therefore, there is no technical content to explain.","46
Abstraction Prompting"
12-reasoning.pdf,46,"The slide contains only the name ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning or natural language processing. There are no concepts, algorithms, equations, or architectures described on this slide.","47
Small LM Reasoning"
12-reasoning.pdf,47,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or NLP concepts, algorithms, architectures, or equations. Therefore, there are no concepts or technical material to explain.","48
Small LM Reasoning"
12-reasoning.pdf,48,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There is no technical content related to ML, NLP, or any other subject to explain.","49
Instruction-tuning Small LMs with CoT Rationales"
12-reasoning.pdf,49,"The slide contains only the title text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","50
Instruction-tuning Small LMs with CoT Rationales"
12-reasoning.pdf,50,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or their relationships. Therefore, there is no relevant technical content on this slide to explain.","51
Instruction-tuning Small LMs with CoT Rationales"
12-reasoning.pdf,51,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships presented on this slide to explain.","52
Evaluate Small LM reasoning on Big-Bench"
12-reasoning.pdf,52,"The slide does not contain any technical content related to ML or NLP concepts, algorithms, equations, or architectures. It only displays the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no information here to explain regarding machine learning or natural language processing.","53
Analysis of LLM Reasoning"
12-reasoning.pdf,53,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to ML or NLP such as concepts, algorithms, equations, or architectures. Therefore, there are no technical concepts to explain from this slide.","54
CoT Rationales are often not faithful"
12-reasoning.pdf,54,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing present on the slide to explain.","55
Reasoning vs Memorization ‚Äì Counterfactuals"
12-reasoning.pdf,55,"The slide contains no technical content related to machine learning, NLP, or related algorithms and concepts. It simply displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" No concepts, equations, architectures, or algorithms are mentioned or depicted.","56
Reasoning vs Memorization ‚Äì Counterfactuals"
12-reasoning.pdf,56,"The slide does not contain any technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures presented on this slide to explain.","57
Reasoning vs Memorization ‚Äì Counterfactuals"
12-reasoning.pdf,57,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical details to explain from this slide.","58
Reasoning vs Memorization ‚Äì Counterfactuals"
12-reasoning.pdf,58,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" without any technical content related to machine learning, natural language processing, algorithms, equations, or architectures. There are no concepts, models, or relationships to explain based on this text.","59
Reasoning vs Memorization ‚Äì Counterfactuals"
12-reasoning.pdf,59,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. It appears to be an image of a building with a text slogan ""LEADING THE CHARGE, CHARGING AHEAD"" at the bottom, which does not pertain to technical ML/NLP topics.",Thank you!
13-retrieval.pdf,0,"There is no technical content, concepts, algorithms, equations, or architectures on this slide to explain. It appears to be a photographic image of a building with no visible technical text or diagrams related to machine learning or NLP.","CIS 6930 Special Topics in Large Language Models
Retrieval Augmented Language Model"
13-retrieval.pdf,1,"The slide contains only text showing the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, or NLP-related content to describe or explain on this slide.","2
Outline
¬É Part 1: Introduction to Retrieval Augmentation
¬É Part 2: Retrieval Augmentation Architectures (main body)
¬É Part 3: Other Interesting Questions of Retrieval Augmentation
¬É Part 4: Future (more open questions)"
13-retrieval.pdf,2,"The slide contains only the institution name ""University of Florida Herbert Wertheim College of Engineering"" and has no technical content related to machine learning or natural language processing to explain.","3
Introduction to Retrieval Augmentation"
13-retrieval.pdf,3,"The slide contains only an institutional header: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide to explain.","4
Traditional Language Model
S = Where are we going
Previous words (context)
Word being predicted
P(S) = P(Where) * P(are | Where) * P(we | Where are) * P(going | Where are we) 
Training objective: maximize the joint probability of the observed text"
13-retrieval.pdf,4,"The slide contains only the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP present on this slide for explanation.","5
Next Word Prediction
Plain vanilla sequence-to-token
Problems:
¬É Lack user interface
Solutions:
¬É Prompt your model
¬É Instruction tune your model to follow prompts
¬É Align your model with human preferences
Input
Generator
Output"
13-retrieval.pdf,5,"There is no technical content related to machine learning or natural language processing on this slide to explain. The slide contains only the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering.""","6
Prompt-Tuned Language Model
Problems:
¬É Hallucination
¬É Attribution
¬É Staleness
¬É Revisions
¬É Customization
Solutions:
¬É Contextualized to external memory (RAG)
Input
Generator
Output
Prompt"
13-retrieval.pdf,6,"There is no technical content related to machine learning or natural language processing on this slide. It contains only the text stating the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering.""","7
Contextualization
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs"
13-retrieval.pdf,7,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain from this slide.","8
Two Paradigms
¬É Closed book (knowledge in parameters) vs Open book (external 
source)
¬É Parametric vs Non-parametric / Semi-parametric"
13-retrieval.pdf,8,"The slide does not contain any technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships presented on this slide.","9
Why does RAG solve the issues?
¬É Choosing contextualized documents allows customization, which 
means you can revise NQRZOHGJHDQGGRQ¬∂WVXIIHUIURPstaleness
¬É Grounding means you have less hallucinations, and you can do 
citations and attribution by pointing back to the source"
13-retrieval.pdf,9,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing.","10
Retrieval Augmentation Architectures"
13-retrieval.pdf,10,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering.""","11
Designs of Retrieval Augmentation Architectures
¬É What happens during training?
Update the generator (LM)? Update the query encoder? Update the 
document encoder? Update all? Pretrain from scratch or not?
¬É What happens during inference?
Different or same retrieved documents? etc."
13-retrieval.pdf,11,"The slide contains only the heading ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","12
I. Frozen RAG
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs
LM prompts is hand-tuned 
to maximize in-context 
learning performance
¬É No training, in-context learning only
¬É Everything frozen"
13-retrieval.pdf,12,"The slide contains only the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""

It does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures.","13
II. Contextualization via Retrieval
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs"
13-retrieval.pdf,13,"The slide contains only the name of the institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to describe. Please provide a slide with relevant technical material for explanation.","14
Sparse Retrieval
¬É TF-IDF and BM25 (variant of TF-IDF) (Robertson, Sparck-Jones et al)
¬É Used in DrQA (Chen et al., 2017)"
13-retrieval.pdf,14,"The slide contains only a university name and does not include any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there are no technical concepts, models, algorithms, or equations to explain from this slide.","15
Dense Retrieval
¬É OrQA (Lee et al., 2019)
¬É Dense Passage Retriever (Karpukhin, Oguz et al., 2020)
Dot Product Õ¥ 
semantic similarity"
13-retrieval.pdf,15,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain from this slide.","16
Dense Retrieval beyond Dot Product
¬É ColBERT (Khattab et al., 2020) ¬± how do query and documents interact
Cross-encoders
all-to-all interactions
Separate encoders
NN to learn similarity
ColBERT (late interaction)"
13-retrieval.pdf,16,"The slide contains no technical content to explain. It only displays the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name and not related to machine learning or NLP concepts.","17
Sparse Retrieval vs Dense Retrieval
¬É Sparse Representation (lexical)
Corresponding actual specific words
Easier to interpret how documents are ranked by a given query
Low cost for building new sparse search engine infrastructure
¬É Dense Representation (semantic)
Contextualized representation
Empirically better performances
Easier to scale for efficient implementation"
13-retrieval.pdf,17,"The slide appears to contain only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there are no technical concepts, equations, architectures, or relationships to explain based on this slide.","20
III. Contextualizing the Retriever for the Generator
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs"
13-retrieval.pdf,18,"The slide contains only the name and affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning, natural language processing, or related concepts present on the slide.","21
Generator as a frozen black-box LM
¬É RePlug (Shi et al., 2023) ¬± inference"
13-retrieval.pdf,19,"The slide contains only the title ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical content on this slide to describe.","22
Generator as a frozen black-box LM
¬É RePlug (Shi et al., 2023) ¬± training"
13-retrieval.pdf,20,"The slide does not contain any technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering."" Please provide a slide with relevant technical information for explanation.","23
IV. Contextualization via retrieve-rerank
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs
Re-
ranker
Specialize only 
the retrieval part 
via reranking"
13-retrieval.pdf,21,"The content on this slide is only the name of the institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","24
V. Contextualization of both
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs"
13-retrieval.pdf,22,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related concepts, algorithms, or architectures. Therefore, there are no technical concepts to explain from this slide.","25
Fine-tune both generator and retriever
¬É RAG (Lewis et al., 2020)"
13-retrieval.pdf,23,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations. There is no technical material to explain or analyze in this slide.","26
Two Types of RAG
¬É RAG (Lewis et al., 2020)"
13-retrieval.pdf,24,"The slide only contains a header text indicating the affiliation with the University of Florida Herbert Wertheim College of Engineering and does not display any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there are no technical topics to explain from this slide.","27
Fusion in the Decoder ¬± increase k
¬É FiD (Izacard & Grave 2020)
Address the limitation of small k in RAG ¬± fusion in the decoder directly"
13-retrieval.pdf,25,"The slide does not contain any technical content related to machine learning or natural language processing. It only displays the text identifying the ""University of Florida Herbert Wertheim College of Engineering,"" which is likely a header or title rather than a concept, algorithm, equation, or architecture explanation.","28
Generator with kNN-based retriever
¬É kNN-LM (Khandelwal et al., 2019)
late interpolation of parametric LM and non-parametric kNN retriever"
13-retrieval.pdf,26,"This slide only contains the name of an academic institution, namely ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP/ML content presented on this slide to explain.","29
VI. Contextualization all the way
Input
Generator
Output
Prompt
Context
Query 
Encoder
Retriever
Doc Encoder
Docs
expensive"
13-retrieval.pdf,27,"The slide contains only the institution name ""University of Florida Herbert Wertheim College of Engineering"" and no technical content related to machine learning or natural language processing concepts. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","30
Backpropagate all the way
¬É REALM (Guu et al., 2020)
A classical work of non-frozen 
retrieval augmented LMs
Signal from language modeling 
objective backpropagates all the 
way through the retriever, query 
encoder, and document encoder"
13-retrieval.pdf,28,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, or architectures to explain from this slide.","31
Other Interesting Questions of Retrieval Augment"
13-retrieval.pdf,29,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical topics to explain from this slide.","32
Other Interesting Questions
¬É When to retrieve?
¬É Legal risk of training or retrieval data source?
¬É Does the order of retrieved documents matter?
¬É Extension of retrieval augmentation?
¬É Combine with instruction tuning?
¬É Multimodal RAG?"
13-retrieval.pdf,30,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain.","33
When to Retrieve
¬É FLARE (Jiang, Xu, 
Gao, Sun et al., 2023)
LM will decide when to 
retrieve and when not"
13-retrieval.pdf,31,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional title, not related to any specific machine learning or natural language processing technical content. There are no concepts, algorithms, equations, or architectures presented to explain.","34
Isolating legal risk with retrieval
¬É SILO (Min, Gururangan et al., 2023)
Parametric LM 
under training
Non-parametric 
data store for 
testing-time 
retrieval"
13-retrieval.pdf,32,"The slide only shows the title ""University of Florida Herbert Wertheim College of Engineering"" and contains no technical content related to machine learning or natural language processing concepts, algorithms, or architectures to explain.","35
The order of retrieved documents
¬É Liu et al., 2023
lost in the middle when LM use 
long contexts
LM attend more to beginning and 
latter tokens, but less to the middle"
13-retrieval.pdf,33,"There is no technical content on the slide to describe. It only contains the name ""University of Florida Herbert Wertheim College of Engineering."" Please provide a slide with technical content related to machine learning or natural language processing for explanation.","36
Extension of Retrieval Augmentation
¬É WebGPT (Nakano et al., 2021)
The retrieved documents can be replaced by anything"
13-retrieval.pdf,34,"The slide heading indicates it is from the University of Florida Herbert Wertheim College of Engineering, but there is no presentation content visible in the image to describe or explain. Please provide the slide content or text to proceed with a technical explanation of the ML/NLP concepts.","37
Extension of Retrieval Augmentation
¬É Toolformer (Shick et al., 2021)
Can be generalized to all kinds of tools"
13-retrieval.pdf,35,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only includes the name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical details to explain on this slide.","38
Combined with Instruction Tuning
¬É InstructRetro (Wang et al., 2023)
¬É RA-DIT (Lin, Chen et al, 2023)"
13-retrieval.pdf,36,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering.""","39
Multimodal RAG
¬É Gur et al., 2021
¬É Yasunaga et al, 2023"
13-retrieval.pdf,37,"The slide contains only the name of an educational institution and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain.","40
Future ¬± more open questions"
13-retrieval.pdf,38,"The slide contains no technical content related to Machine Learning or Natural Language Processing concepts, algorithms, equations, architectures, or their relationships. It only shows the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering.""","41
More open questions
¬É Joint from-scratch pretraining is still underexplored
¬É What do scaling laws look like? (Scale LM in terms of params or 
tokens, Scale the retriever in terms of params or chucks, Scale the 
index size during inference)
¬É Can we fully decouple memorization from generalization, decouple 
knowledge from generation?
¬É Are there smart ways to create synthetic data for RAG?
¬É How do we properly evaluate RAG system?
¬É Zero-shot domain generalization"
13-retrieval.pdf,39,"There is no visible technical content, concepts, algorithms, equations, or architectures related to ML/NLP on this slide. The slide contains an image of a modern building and text ""LEADING THE CHARGE, CHARGING AHEAD,"" which does not pertain to ML or NLP concepts.",Thank you!
14-knowledge.pdf,0,"The slide contains no technical content to explain. It features an image of a building and the phrase ""Leading the Charge, Charging Ahead"" but includes no concepts, algorithms, equations, architectures, or NLP/ML-related information.","CIS 6930 Special Topics in Large Language Models
Knowledge Augmented Language Model"
14-knowledge.pdf,1,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not provide any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical details to explain from this slide.","Outline
¬ß Introduction to Knowledge-augmented LM
¬ß Methods to add knowledge into LM
1. Add pretrained entity embeddings
2. Modify the training data
¬ß Evaluating knowledge in LM"
14-knowledge.pdf,2,"The text on the slide states ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" This is an institutional or organizational title and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations to explain.",Introduction to Knowledge-augmented LM
14-knowledge.pdf,3,"The slide does not contain any technical content related to ML or NLP. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which refers to an educational institution or department, not a technical concept or algorithm. Please provide a slide containing ML/NLP-specific content for explanation.",What does LM know?
14-knowledge.pdf,4,"The slide header indicates that it is from the University of Florida Herbert Wertheim College of Engineering, which suggests this is an engineering or computer science related educational course.

However, as this slide contains only the header with no other technical content such as concepts, algorithms, equations, or architectures, there are no ML or NLP-specific technical topics to explain from this slide beyond identifying the institution. To provide a technical explanation, I would need content related to language models, algorithms, model architectures (e.g., transformers, RNNs), or evaluation metrics typically found in an ML/NLP course.",What does LM know?
14-knowledge.pdf,5,"The text on the slide states the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP presented in this text. It is purely an institutional name without any technical content to explain.",Why build Knowledge-aware LM
14-knowledge.pdf,6,"The content displayed is simply the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP on this slide.",Traditional Knowledge Base
14-knowledge.pdf,7,"This slide contains only the text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING.""

There is no technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP on this slide to explain.",Query Language Models as Knowledge Bases
14-knowledge.pdf,8,"The content on the slide, ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" is a header or title indicating the institutional affiliation or source of the material. It does not contain technical concepts, algorithms, equations, architectures, or relationships related to Machine Learning or Natural Language Processing. Therefore, there are no technical details to explain from this slide.",Advantage of using LM over traditional KB
14-knowledge.pdf,9,"The slide title indicates affiliation with the University of Florida Herbert Wertheim College of Engineering, but there is no technical content related to machine learning or natural language processing concepts, algorithms, or architectures visible here to describe. Please provide a slide or image containing specific ML or NLP concepts for explanation.",Methods to add knowledge into LM
14-knowledge.pdf,10,"The content on the slide, indicated by the text, is a title referring to the ""University of Florida Herbert Wertheim College of Engineering."" This is an institutional name and not technical content related to machine learning or natural language processing.

There are no ML/NLP concepts, algorithms, equations, architectures, or relationships presented on this slide for me to explain. If you provide slides with technical content, I can explain them accordingly.","Methods to add knowledge into LM
¬ß Method 1: Add pretrained entity embeddings
ERNIE: Enhanced Language Representation with Informative Entities [Zhang et al., ACL 19] 
GreaseLM: Reasoning with Language Model and Knowledge Graph [Zhang et al. ICLR 2022] 
¬ß Method 2: Modify the training data
WKLM [Xiong et al., ICLR 2020] 
ERNIE1: Enhanced Representation through Knowledge Integration [Sun et al., 2019]"
14-knowledge.pdf,11,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not include any technical content related to machine learning, natural language processing, or related topics such as algorithms, models, or equations. Therefore, there are no concepts or technical details to explain.",Method 1: Add pretrained entity embeddings
14-knowledge.pdf,12,"The text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" is the name of an institution and not technical ML/NLP content. There are no concepts, algorithms, equations, or architectures related to machine learning or natural language processing to describe here. Please provide a slide with relevant technical content for explanation.",Method 1: Add pretrained entity embeddings
14-knowledge.pdf,13,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which does not present any technical machine learning or natural language processing content such as concepts, algorithms, equations, or architectures. 

Therefore, there are no ML/NLP technical concepts to explain from this slide.",What is Entity Linking
14-knowledge.pdf,14,"The slide content ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" is a title or header indicating the institution and college affiliation. There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing presented in this slide text.",Method 1: Add pretrained entity embeddings
14-knowledge.pdf,15,"The text on this slide identifies the University and the specific engineering college, which is the Herbert Wertheim College of Engineering at the University of Florida. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.",Method 1: Add pretrained entity embeddings
14-knowledge.pdf,16,"This slide contains only a text header indicating the affiliation or institution: ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. There are no technical terms, definitions, or explanation on this slide to analyze or explain.",Method 1: Add pretrained entity embeddings (ERNIE)
14-knowledge.pdf,17,"The text on this slide is the name of an academic institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented in this slide. It appears to be a title or header slide for a course or presentation rather than content focused on ML/NLP topics.",Method 1: Add pretrained entity embeddings (ERNIE)
14-knowledge.pdf,18,The slide header identifies the institution but contains no technical content itself. Please provide the slide with the technical material to explain.,Method 1: Add pretrained entity embeddings (ERNIE)
14-knowledge.pdf,19,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. There are no concepts, algorithms, architectures, or equations displayed on it to explain.",Method 1: Add pretrained entity embeddings (ERNIE)
14-knowledge.pdf,20,"The slide itself contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or other related concepts. Therefore, there are no concepts, algorithms, equations, or architectures to explain from this slide.",Method 1: Add pretrained entity embeddings (ERNIE)
14-knowledge.pdf,21,"The slide contains no technical content related to machine learning or natural language processing. It displays only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is the name of an educational institution and does not involve any ML/NLP concepts, algorithms, equations, architectures, or their relationships.",Method 1: Add pretrained entity embeddings (GreaseLM)
14-knowledge.pdf,22,"This slide contains only the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" 

There is no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or other relevant topics present on this slide for explanation.",Method 2: Modify the training data
14-knowledge.pdf,23,"The slide contains only a heading indicating an institution name: ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships to explain.",Method 2: Modify the training data
14-knowledge.pdf,24,"This slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP presented on this slide.",Method 2: Modify the training data (WKLM)
14-knowledge.pdf,25,"The text on this slide is a header indicating the institution and college: ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning or natural language processing concepts, algorithms, or equations present on this slide.",Method 2: Modify the training data (WKLM)
14-knowledge.pdf,26,"The slide contains no technical content related to ML/NLP concepts, algorithms, equations, architectures, or relationships. It only displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""",Method 2: Modify the training data (WKLM)
14-knowledge.pdf,27,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to ML/NLP, algorithms, concepts, or equations. There are no concepts, models, architectures, or equations to explain on this slide.",Method 2: Modify the training data (WKLM)
14-knowledge.pdf,28,"The content in the image is a title or header stating ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or NLP/ML-related content presented on this slide to explain. It appears to be an institutional or course identification header rather than technical material.",Method 2: Modify the training data (ERNIE1)
14-knowledge.pdf,29,"The text on this slide identifies the institution and college, specifically the University of Florida's Herbert Wertheim College of Engineering. It doesn't contain any technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations.",Evaluation
14-knowledge.pdf,30,"The slide contains only a textual header: ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented here. Therefore, there is no technical material to explain on this slide.",Knowledge-intensive downstream tasks
14-knowledge.pdf,31,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is a title indicating the academic institution and specific college. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning, NLP, or any other technical topic presented on this slide.",Relation Extraction Performance on TACRED
14-knowledge.pdf,32,"The slide header indicates the institutional affiliation, specifically the University of Florida's Herbert Wertheim College of Engineering. This is typically the heading or title section used in course materials and does not contain technical machine learning or natural language processing content. 

To proceed with a technical explanation, please provide a slide that includes concepts, algorithms, equations, architectures, or relationships related to ML or NLP.",Entity Typing Performance on OpenEntity
14-knowledge.pdf,33,"The slide header indicates affiliation with the University of Florida‚Äôs Herbert Wertheim College of Engineering but contains no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. There are no equations, models, or technical relationships to explain on this slide.",Knowledge-intensive Question Answering
14-knowledge.pdf,34,"The slide contains no technical content related to machine learning or natural language processing such as concepts, algorithms, equations, or architectures. It only shows a background image of a building and a phrase ""LEADING THE CHARGE, CHARGING AHEAD"" at the bottom.",Thank you!
2-ngram-lm.pdf,0,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It appears to be an image of a building exterior and includes the phrase ""LEADING THE CHARGE, CHARGING AHEAD,"" which does not convey technical ML/NLP information.","CIS 6930 Special Topics in Large Language Models
N-gram Language Models"
2-ngram-lm.pdf,1,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any concepts, algorithms, equations, architectures, or technical content related to machine learning or natural language processing. Therefore, there is no technical content to explain.","2
Language Models (LM)
‚ñ™LM should have the ability to assign each possible sequence of 
tokens ùë§1, ‚Ä¶ , ùë§ùëõ‚ààùëâ with a meaningful probability: ùëùùë§1, ‚Ä¶ , ùë§ùëõ
ùëùùë§1, ‚Ä¶ , ùë§ùëõ
= p ùë§1  ‚àó ùëùùë§2 ùë§1  ‚àóùëùùë§3 ùë§1, ùë§2 ‚àó ‚Ä¶ ‚àóùëù(ùë§ùëõ|ùë§1, ùë§2, ‚Ä¶ , ùë§ùëõ‚àí1)
E.g. p(cat sat on the mat) = p(cat) * p(sat | cat) * p(on | cat sat) * 
 
 
 
 
p(the | cat sat on) * p(mat | cat sat on the)"
2-ngram-lm.pdf,2,"The slide contains only the name ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning, natural language processing, or related computational concepts. There are no algorithms, equations, models, or relationships described on this slide.","3
Language Models (LM)
‚ñ™LM should have the ability to assign each possible sequence of 
tokens ùë§1, ‚Ä¶ , ùë§ùëõ‚ààùëâ with a meaningful probability: ùëùùë§1, ‚Ä¶ , ùë§ùëõ
‚ñ™LM is a machine learning model that assigns a probability for each 
possible next word ùëùùë§ùëõ |ùë§1, ‚Ä¶ , ùë§ùëõ‚àí1  (predicting upcoming words)
‚ñ™This is how LLM work: (1) LLMs are trained to predict words (2) 
LLMs generate text by predicting the next word repeatedly."
2-ngram-lm.pdf,3,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering"" which is the name of an institution. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","4
N-gram Language Model
‚ñ™N-gram Language Model ‚Äì the simplest kind of language model
‚ñ™What is n-gram: n-gram is a sequence of n words
2-gram (bigram) = two-word sequence of words, e.g. the cat, cat sat‚Ä¶
3-gram (trigram) = three-word sequence of words, e.g. the cat sat ‚Ä¶
‚ñ™N-gram LM is a probabilistic model that can estimate the prob of a 
word given the N-1 previous words, and thereby to assign prob for 
entire sequences"
2-ngram-lm.pdf,4,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships to explain here.","5
Outline
‚ñ™Building N-gram Language Model
‚ñ™Generation from N-gram Language Model
‚ñ™Evaluating N-gram Language Model
‚ñ™Smoothing of N-gram Language Model"
2-ngram-lm.pdf,5,"The slide contains no technical content related to machine learning, natural language processing, or any related concepts, algorithms, equations, or architectures. It only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be an institutional or college name.","6
Building a N-gram Language Model"
2-ngram-lm.pdf,6,"The slide content ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" does not contain any technical content related to machine learning or natural language processing. Please provide a slide with technical material such as concepts, algorithms, equations, or architectures for explanation.","7
How to estimate probability
‚ñ™One way to estimate ùëù(ùë§|‚Ñé) prob of a word ùë§ given some history ‚Ñé is 
using relative frequency counts"
2-ngram-lm.pdf,7,"The text on the slide only contains the name ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical content to explain from this slide. If you have another slide with ML/NLP content, please share it!","8
Problems of relative frequency counts
‚ñ™Not accurate because new sentences are invented all the time
   Even the entire web is not big enough to give us good estimates for   
   counts of every possible sentences
‚ñ™Computational heavy for sequence with long length n
  With a vocabulary of size V, # sequence of length n = ùëâùëõ
  Typical English vocabulary V ~ 40k words
  Even sentences of length <= 11 results in more than 4 x 1050 sequences"
2-ngram-lm.pdf,8,"The slide appears to contain only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.

Therefore, there are no technical concepts or details to explain based on this slide.","9
Markov Assumption
‚ñ™Markov Assumption definition ‚Äì the future state conditioned on the 
current state (or recent several states) is independent of past states
‚ñ™Use only the recent past to predict the next word
1-st order
2-nd order"
2-ngram-lm.pdf,9,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","10
N-gram Language Model
‚ñ™Instead of computing the prob of word given its entire history, we only 
use the last N-1 steps to approximate all the history
ùëùùë§1, ‚Ä¶ , ùë§ùëõ= ‚àèùëñ ùëùùë§ùëñùë§ùëñ‚àíùëÅ+1, ‚Ä¶ , ùë§ùëñ‚àí1)"
2-ngram-lm.pdf,10,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented here. Therefore, there is no technical content to explain.","11
N-gram Language Model
                                 ùëùùë§ùëñ |ùë§ùëñ‚àí1 = ùê∂(ùë§ùëñ‚àí1,ùë§ùëñ )
ùê∂(ùëäùëñ‚àí1)
Larger N, more accurate and better the LM is, but also higher costs"
2-ngram-lm.pdf,11,"The slide contains only the name of an institution and does not present any technical content related to machine learning, natural language processing, or any algorithms, models, or mathematical concepts. Therefore, there are no concepts, architectures, equations, or relationships to explain from this slide.","12
Practice ‚Äì Estimating Conditional Probabilities"
2-ngram-lm.pdf,12,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any technical content related to machine learning, natural language processing, or related concepts. There are no algorithms, equations, architectures, or relationships described on the slide.","13
Practice ‚Äì Estimating Conditional Probabilities"
2-ngram-lm.pdf,13,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or other related topics. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain from this slide.","14
Practice ‚Äì Estimating Joint Probabilities"
2-ngram-lm.pdf,14,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. Therefore, there is no technical content to explain.","15
Practice ‚Äì Estimating Joint Probabilities"
2-ngram-lm.pdf,15,"The slide contains no technical content related to machine learning or natural language processing concepts. It only shows an institutional name, ""University of Florida Herbert Wertheim College of Engineering."" There are no algorithms, equations, architectures, or relationships to explain here.","16
Scaling in Large N-gram Models ‚Äì Log Probability
‚ñ™Probability Numerical Underflow: Because probabilities are <= 1, the 
more probs we multiply together, the smaller the product becomes
‚ñ™Log Probability: adding in log space is equivalent to multiplying in linear 
space, and we get results that are not small"
2-ngram-lm.pdf,16,"The slide only contains a text line indicating the institution ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning, natural language processing, or related algorithms and concepts. Therefore, there are no technical concepts, equations, or architectures to explain from this slide.","17
Generation from N-gram Language Model"
2-ngram-lm.pdf,17,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content, concepts, algorithms, equations, or architectures related to machine learning or natural language processing. Therefore, there is no technical content to explain from this slide.","18
Sampling a word from a prob distribution"
2-ngram-lm.pdf,18,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. There is no technical material to explain.","19
Generating sequences from bigram LM"
2-ngram-lm.pdf,19,"The slide's text is simply the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" It does not contain any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing.","20
Generating sequences from bigram LM"
2-ngram-lm.pdf,20,"The slide contains only the phrase ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. There are no NLP or ML topics to explain from this slide.","21
Generating sequences from trigram LM"
2-ngram-lm.pdf,21,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any technical content related to machine learning, natural language processing, algorithms, equations, or architectures. There are no NLP or ML concepts, models, or mathematical expressions to explain.","22
Evaluating N-gram Language Model"
2-ngram-lm.pdf,22,"The text on this slide is ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical topics to explain from this slide.","23
Two types of evaluation for LM
‚ñ™Extrinsic Evaluation
Train LM -> apply to downstream task -> evaluate the task
Higher task performance -> better model
Problem: expensive, time consuming, indirect feedback"
2-ngram-lm.pdf,23,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain from this slide.","24
Two types of evaluation for LM
‚ñ™Intrinsic Evaluation
Measures the quality of a LM independent of any application
How well a LM estimates the probability of sequences
How to evaluate: training set, testing set, development set, metric"
2-ngram-lm.pdf,24,"The slide text contains no technical content related to machine learning or natural language processing. It only shows the affiliation ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and thus includes no concepts, algorithms, equations, architectures, or relationships to explain.","25
Intrinsic Evaluation ‚Äì split datasets
‚ñ™Training set: is the data we use to learn the parameter of model
For the N-gram LM, training data is the data from which we get the n-
gram counts to estimate n-gram probability
‚ñ™Testing set: is a set of unseen data that is not overlapping with training 
set, that we use to evaluate the model
If a LM assigns a higher probability to the test set, that means it more 
accurately predicts the test set, then it is a better model.
‚ñ™Development set: used to tune hyper-parameter"
2-ngram-lm.pdf,25,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional affiliation. There are no technical concepts, algorithms, equations, or architectures presented on this slide to explain.","26
Intrinsic Evaluation ‚Äì metric
‚ñ™Recall: if a LM assigned a higher probability to the test set, it is better
‚ñ™Question: Can we use probability as the evaluation metric?
We do not use the raw probability as the metric, because the prob of a 
test set depends on the number of words/tokens ‚Äì the prob gets smaller if 
the test text is longer.
‚ñ™Metric: Perplexity (a metric normalized by sequence length, per-word)"
2-ngram-lm.pdf,26,"The slide contains no technical content related to machine learning or natural language processing. It only shows the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" No concepts, algorithms, equations, architectures, or relationships are presented on this slide.","27
Intrinsic Evaluation ‚Äì perplexity
‚ñ™Perplexity has an inverse relation with probability
‚ñ™Better LM = higher estimated probability on test set = lower perplexity"
2-ngram-lm.pdf,27,"The slide contains a single line of text stating the institutional affiliation: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING.""

There are no technical concepts, algorithms, equations, architectures, or related content present on this slide to analyze or explain.","28
Intrinsic Evaluation ‚Äì perplexity
‚ñ™Example: unigram, bigram, trigram models on 38M words from the Wall 
Street Journal news paper, their perplexity on test corpus (1.5M words)
Trigram model gives us more information about word sequence, has a 
better idea of what words might come next, thus assigns a higher prob"
2-ngram-lm.pdf,28,"The slide contains only a text header mentioning the ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content‚Äîsuch as concepts, algorithms, equations, or architectures‚Äîrelated to machine learning or NLP present on this slide.","29
Intrinsic Evaluation ‚Äì perplexity"
2-ngram-lm.pdf,29,"The slide contains only the name of an institution: ""University of Florida Herbert Wertheim College of Engineering.""

There is no technical content, algorithm, or concept related to machine learning or natural language processing on this slide to explain.","30
Smoothing of N-gram Language Model"
2-ngram-lm.pdf,30,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, algorithms, or architectures. Therefore, there are no concepts, equations, or relationships to explain from this slide.","31
Problem of N-gram Language Model
‚ñ™Not all n-grams in the test set will be observed in training data
Example: Training set is Google News, Testing set is Shakespeare
P(affray | voice doth us) = 0
‚ñ™Problem of a particular n-gram never occurs in the training but appears 
in the test set:
(1) Underestimate the probability of words sequences that might occur
(2) The prob of the whole test set will also be 0, perplexity no sense"
2-ngram-lm.pdf,31,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, architectures, equations, or technical relationships presented on this slide to explain.","32
Smoothing
Smoothing is to make sure the probabilities for all the possible n-gram are 
non-zero in our model
‚ñ™Laplace Smoothing: Adding a small amount to all probabilities
‚ñ™Interpolation: Combining different granularities of n-gram LM
‚ñ™Backoff: Backing off to lower n-gram"
2-ngram-lm.pdf,32,"The slide only displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical details to explain from this slide.","33
Smoothing ‚Äì Laplace Smoothing
Adding a small amount to all probabilities"
2-ngram-lm.pdf,33,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" as a heading or banner. There are no technical concepts, algorithms, equations, architectures, or relationships presented on this slide that pertain to Machine Learning or Natural Language Processing.","34
Smoothing ‚Äì Linear Interpolation
Combining different granularities of n-gram LM to estimate probability
Process: (1) estimate n-gram prob on training set (2) tune hyper-
parameter (lambdas) to maximize prob on dev set (3) evaluate on test set"
2-ngram-lm.pdf,34,"The slide content is only the phrase ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name. There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP presented on this slide to explain.","35
Smoothing ‚Äì Backoff
If the n-gram we need has zero counts, we approximate it by backing off 
to the (n-1) gram, until we reach a history that has non-zero counts."
2-ngram-lm.pdf,35,There is no visible technical content on this slide to describe.,Thank you!
2-ngram-lm.pdf,36,"The slide contains only the name ‚ÄúUniversity of Florida Herbert Wertheim College of Engineering‚Äù and does not include any technical content related to machine learning, natural language processing, models, algorithms, equations, or architectures. Therefore, there are no technical concepts to describe from this slide.","37
References
Speech and Language Processing (3rd ed. draft)
Dan Jurafsky and James H. Martin
Chapter 3"
3-llm-tokenization.pdf,0,"The slide contains no visible technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. It appears to be a styled background image with some design elements but no instructional or technical material to describe.","CIS 6930 Special Topics in Large Language Models
LLM Tokenization"
3-llm-tokenization.pdf,1,"The slide shown contains only a university name and college name text: ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, or related algorithms or models.

Please provide a slide with technical content such as concepts, equations, architectures, or algorithms, so I can explain the relevant material.","2
Outline
‚ñ™Introduction of Tokenization
  (what is tokenization, why we need tokenization)
‚ñ™Na√Øve ways of Tokenization
‚ñ™Classical Algorithms for Tokenization used in LLMs"
3-llm-tokenization.pdf,2,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or technical relationships to explain.","3
What is Tokenization
‚ñ™Recall: a LM is a probability distribution over a sequence of tokens 
where each token comes from some vocabulary V
  
‚ñ™However, natural language doesn‚Äôt come as a sequence of tokens, 
but just as a string"
3-llm-tokenization.pdf,3,"The slide contains only text indicating an institutional affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or other NLP/ML content presented on this slide to explain.","4
What is Tokenization
‚ñ™Tokenization is a process that converts any text string into a 
sequence of tokens, which can be words, sub-words, characters
‚ñ™These tokens are the smallest units of meaning in a text that can be 
processed by a LM"
3-llm-tokenization.pdf,4,"The slide contains only a text header stating ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content, algorithm, or concept related to machine learning or natural language processing to explain.","5
Why we need Tokenization
‚ñ™The language data is in textual form, but language model (or any 
machine learning models) process numbers, and tokenization helps 
convert text into numbers that is readable by models
‚ñ™LLM training and inference workflows need to process each token as 
unique integer, and map each unique integer into a vector embedding, 
and feed vector embedding as input into language model"
3-llm-tokenization.pdf,5,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, or architectures present on this slide related to machine learning or natural language processing.","6
Why we need Tokenization
‚ñ™LLM training workflows: text -> tokens -> unique integer -> vector 
embeddings in the lookup table -> input into language model
Unique integer corresponds to row id in the lookup table
Lookup table: each row represents vector embedding of each token
Token
Unique
Integer
‚Ä¶
Lookup
Table
LLM first 
layer"
3-llm-tokenization.pdf,6,"The slide shows a heading indicating the affiliation with the University of Florida Herbert Wertheim College of Engineering. It does not present any technical content related to machine learning, natural language processing, or related algorithms, architectures, or concepts. Therefore, there is no technical material on this slide to explain.","7
Why we need Tokenization
Model inside illustration"
3-llm-tokenization.pdf,7,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not include any technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no technical content to explain from this slide.","8
Why we need Tokenization
‚ñ™LLM inference workflows: vector embeddings of each token (after layer 
of layer propagation in LLM) -> unique integer for each token -> text
Token
Unique
Integer
‚Ä¶
LLM output 
embeddings
Learn a mapping 
function (neural 
network layers)"
3-llm-tokenization.pdf,8,"The slide contains only a text heading identifying the institution as ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content, concepts, algorithms, equations, or architectures provided on this slide to describe or explain related to machine learning or natural language processing.","9
Na√Øve Ways of Tokenization"
3-llm-tokenization.pdf,9,"The slide only shows the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content, concepts, algorithms, equations, or architectures related to machine learning or natural language processing to describe here.","10
Split by spaces
The simplest solution is to split by spaces"
3-llm-tokenization.pdf,10,"The slide contains only the title ""University of Florida Herbert Wertheim College of Engineering"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material to explain.","11
Split by spaces
There exists several problems:
‚ñ™That doesn‚Äôt work for some languages, such as Chinese, where 
sentences are written without spaces between words
‚ñ™There are languages, such as German, that have long compound 
words (e.g., Abwasserbehandlungsanlange)
‚ñ™Even in English, there are hyphenated words(e.g., ‚Äúfather-in-law‚Äù) or 
contraction (e.g., ‚Äúdon‚Äôt‚Äù), which should get split up"
3-llm-tokenization.pdf,11,"The slide text reads: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

This content does not contain technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing. It appears to be an institutional or college name header.","12
Character-level Tokenization
What about character-level tokenization? (token = character)
‚ñ™Step 1: Find all unique characters in your corpus
‚ñ™Step 2: Decompose each string into characters
‚ñ™Step 3: Map each character into unique integer
‚ñ™Step 4: Create Lookup Table (convert integer into vector embedding)
‚ñ™Step 5: LM is then trained on these vector embeddings of text string"
3-llm-tokenization.pdf,12,"The slide contains only a text header indicating the institution name: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, models, or equations present on this slide to explain.","13
Character-level Tokenization
There exists several problems:
‚ñ™Difficult when dealing with diverse languages:
This method does not account for languages other than the language for 
which you created vocabulary lookup tables
‚ñ™Difficult when dealing with long sequences: 
The vocabulary size is small (number of characters), but the sequence 
length of tokenized sentences will be much larger. Because LLM usually 
has fixed window size, LLM will process much less data at a time."
3-llm-tokenization.pdf,13,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional heading. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","14
Algorithm 1 ‚Äì Byte Pair Encoding Tokenization"
3-llm-tokenization.pdf,14,"The slide does not contain any technical content related to machine learning or natural language processing. It only displays the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or technical relationships presented on this slide.","15
Byte-Pair Encoding (BPE) Tokenization
‚ñ™Used by OpenAI for tokenization when training the GPT models. It‚Äôs 
used by LLMs like GPT, GPT-2, RoBERTa, BART, and DeBERTa.
‚ñ™Core Idea: start with each character as the token, and then iteratively 
combine the token pair that co-occur together most often into new 
token, and gradually form a full vocabulary"
3-llm-tokenization.pdf,15,"The slide displays the name ""University of Florida Herbert Wertheim College of Engineering"" and does not contain any technical content related to machine learning, natural language processing, or related algorithms and concepts. There are no concepts, equations, architectures, or relationships to describe here.","16
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 1: Initialize the vocabulary as a set of characters
Our corpus  (""hug"", 10), (""pug"", 5), (""pun"", 12), (""bun"", 4), (""hugs"", 5)
Initial Vocabulary: [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u""]"
3-llm-tokenization.pdf,16,"The slide contains only the title text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain based on this slide.","17
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 2: Count how often each pair of tokens co-occur
Our corpus
(""h"" ""u"" ""g"", 10), (""p"" ""u"" ""g"", 5), (""p"" ""u"" ""n"", 12), (""b"" ""u"" ""n"", 4), (""h"" ""u"" ""g"" ""s"", 5)
Vocabulary  [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u""]
Count frequency of token pairs: (""h"", ""u"") 15, (""u"", ""g"") 20 ‚Ä¶"
3-llm-tokenization.pdf,17,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or algorithms. Therefore, there are no concepts, algorithms, equations, architectures, or technical relationships to describe from this slide.","18
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 3: Merge the most frequent token pair into new token
Our corpus (""h"" ""u"" ""g"", 10), (""p"" ""u"" ""g"", 5), (""p"" ""u"" ""n"", 12), (""b"" ""u"" ""n"", 4), (""h"" ""u"" ""g"" ""s"", 5)
Vocabulary  [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u""]
Merge Rule learned by tokenizer     (""u"", ""g"") -> ""ug""
Add newly combined token into the vocabulary       add ""ug"" into V"
3-llm-tokenization.pdf,18,"The slide header only contains the name ""University of Florida Herbert Wertheim College of Engineering."" There is no technical content related to machine learning or natural language processing concepts, algorithms, or architectures presented on this slide.","19
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 4: Repeat Iteratively (iteratively merge the token pair that co-occur 
together most often into new token, and add new token into Vocabulary)
Vocabulary: [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u"", ""ug""]
Corpus: (""h"" ""ug"", 10), (""p"" ""ug"", 5), (""p"" ""u"" ""n"", 12), (""b"" ""u"" ""n"", 4), (""h"" ""ug"" ""s"", 
5)
Most frequent pair is (""u"", ""n"") 16 times
Add the second merge rule (""u"", ""n"") -> ""un""
Add new token ""un"" into the vocabulary"
3-llm-tokenization.pdf,19,"The content provided is a title indicating an affiliation with the University of Florida Herbert Wertheim College of Engineering. There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing described on this slide. Please provide a slide containing technical material to explain.","20
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 4: Repeat Iteratively (iteratively merge the token pair that co-occur 
together most often into new token, and add new token into Vocabulary)
Vocabulary: [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u"", ""ug"", ""un""]
Corpus: (""h"" ""ug"", 10), (""p"" ""ug"", 5), (""p"" ""un"", 12), (""b"" ""un"", 4), (""h"" ""ug"" ""s"", 5)
Most frequent pair is (""h"", ""ug"") 15 times
Add the third merge rule (""h"", ""ug"") -> ""hug"" 
Add new token ""hug"" into the vocabulary"
3-llm-tokenization.pdf,20,"The text on the slide references the ""University of Florida Herbert Wertheim College of Engineering,"" which appears to be an institutional header rather than technical content related to machine learning or natural language processing. There are no concepts, algorithms, equations, architectures, or relationships presented in the provided image to explain. 

If you have a slide with specific technical content, please share that, and I can provide a detailed explanation.","21
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Step 5: Stop when we reach the desired vocabulary size
Vocabulary: [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u"", ""ug"", ""un"", ""hug""] 
Corpus: (""hug"", 10), (""p"" ""ug"", 5), (""p"" ""un"", 12), (""b"" ""un"", 4), (""hug"" ""s"", 5)"
3-llm-tokenization.pdf,21,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, or equations related to machine learning or natural language processing presented on this slide.","22
Byte-Pair Encoding (BPE) Tokenization ‚Äì Training
‚ñ™Training Outcome
(1) Vocabulary [""b"", ""g"", ""h"", ""n"", ""p"", ""s"", ""u"", ""ug"", ""un"", ""hug""] 
(2) Merge Rules
(""u"", ""g"") -> ""ug‚Äù
(""u"", ""n"") -> ""un‚Äù
(""h"", ""ug"") -> ""hug"""
3-llm-tokenization.pdf,22,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" without any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, no technical explanation can be provided based on this slide.","23
Byte-Pair Encoding (BPE) Tokenization ‚Äì Tokenize
‚ñ™Step 1: Splitting each words into individual tokens
‚ñ™Step 2: Applying the Merge rules learned in order
Merge Rules
(""u"", ""g"") -> ""ug‚Äù, (""u"", ""n"") -> ""un‚Äù, (""h"", ""ug"") -> ""hug‚Äù
New Word: ""bug"" -> [""b"", ""u"", ""g""] -> [""b"", ""ug""]"
3-llm-tokenization.pdf,23,"The slide displays the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" This is an institutional or college name and does not contain any technical content related to machine learning or natural language processing such as concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical topics to explain from this slide.","24
Byte-Pair Encoding (BPE) Tokenization ‚Äì Tokenize
‚ñ™Step 1: Splitting each words into individual tokens
‚ñ™Step 2: Applying the Merge rules learned in order
Merge Rules
(""u"", ""g"") -> ""ug‚Äù, (""u"", ""n"") -> ""un‚Äù, (""h"", ""ug"") -> ""hug‚Äù
New Word: ""thug"" -> [""[UNK]"",""h"", ""u"", ""g""] 
                  -> [""[UNK]"",""h"", ""ug""]
                  -> [""[UNK]"", ""hug""]"
3-llm-tokenization.pdf,24,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships.

If you provide a slide with such technical content, I can help explain it accordingly.","25
Algorithm 2 ‚Äì WordPiece Tokenization"
3-llm-tokenization.pdf,25,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, or architectures to explain from this slide.","26
WordPiece Tokenization
‚ñ™Used by Google for tokenization when training BERT model. It‚Äôs used by 
language models like BERT, DistilBERT, MobileBERT, MPNET etc.
‚ñ™Core Idea: similar to Byte-Pair Encoding (BPE) tokenization (iteratively 
merge token pair that co-occur most often into new token), but different 
in vocabulary initialization and frequency score calculation"
3-llm-tokenization.pdf,26,"The slide contains no technical content‚Äîonly the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or model architectures presented here to explain.","27
WordPiece Tokenization ‚Äì Training
‚ñ™Step 1: Initialize the vocabulary as a set of characters
Difference: add a prefix ## to all the character inside the word
Our corpus  (""hug"", 10), (""pug"", 5), (""pun"", 12), (""bun"", 4), (""hugs"", 5)
Initial Vocabulary:
[""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u""]
(All the beginning character and inside character preceded by the prefix)"
3-llm-tokenization.pdf,27,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","28
WordPiece Tokenization ‚Äì Training
‚ñ™Step 2: Count how often each pair of tokens co-occur
Difference:
Our corpus: (""h"" ""##u"" ""##g"", 10), (""p"" ""##u"" ""##g"", 5), (""p"" ""##u"" ""##n"", 12), 
(""b"" ""##u"" ""##n"", 4), (""h"" ""##u"" ""##g"" ""##s"", 5)
Vocabulary  [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u""]
Calculate score of token pairs: (""##u"", ""##g"") 20/(36*20)
                       (""##g"", ""##s"") 5/(20*5) ‚Ä¶"
3-llm-tokenization.pdf,28,"The slide contains only a text header indicating the affiliation: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"". There is no technical content such as concepts, algorithms, equations, or architectures presented on this slide to explain.","29
WordPiece Tokenization ‚Äì Training
‚ñ™Step 3: Merge the token pair with the highest score into new token
Our corpus: (""h"" ""##u"" ""##g"", 10), (""p"" ""##u"" ""##g"", 5), (""p"" ""##u"" ""##n"", 
12), (""b"" ""##u"" ""##n"", 4), (""h"" ""##u"" ""##g"" ""##s"", 5)
Vocabulary  [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u""]
Merge Rule learned by tokenizer     (""##g"", ""##s"") -> (""##gs"")
Add newly combined token into the vocabulary       add ‚Äù##gs"" into V"
3-llm-tokenization.pdf,29,"The slide contains only an institutional header ""University of Florida Herbert Wertheim College of Engineering"" and no technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there are no technical concepts, equations, or relationships described on this slide to explain.","30
WordPiece Tokenization ‚Äì Training
‚ñ™Step 4: Repeat Iteratively (iteratively merge the token pair with the 
highest score, and add new token into Vocabulary)
Vocabulary: [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs""] 
Corpus: (""h"" ""##u"" ""##g"", 10), (""p"" ""##u"" ""##g"", 5), (""p"" ""##u"" ""##n"", 12), (""b"" 
""##u"" ""##n"", 4), (""h"" ""##u"" ""##gs"", 5)
The pair with highest score is (""h"", ""##u"") 
Merge rule (""h"", ""##u"") -> ""hu"" 
Add new token ""hu"" into the vocabulary"
3-llm-tokenization.pdf,30,"The slide displays the name ‚ÄúUniversity of Florida Herbert Wertheim College of Engineering‚Äù and does not contain technical content related to machine learning or natural language processing concepts, algorithms, or equations. Therefore, there is no technical material to explain from this slide.","31
WordPiece Tokenization ‚Äì Training
‚ñ™Step 4: Repeat Iteratively (iteratively merge the token pair with the 
highest score, and add new token into Vocabulary)
Vocabulary: [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs"", ""hu""]
Corpus: (""hu"" ""##g"", 10), (""p"" ""##u"" ""##g"", 5), (""p"" ""##u"" ""##n"", 12), (""b"" ""##u"" 
""##n"", 4), (""hu"" ""##gs"", 5)
The pair with highest score is (""hu"", ""##g"")
Merge rule (""hu"", ""##g"") -> ""hug"" 
Add new token ""hug"" into the vocabulary"
3-llm-tokenization.pdf,31,"The slide displays only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP presented on this slide.","32
WordPiece Tokenization ‚Äì Training
‚ñ™Step 5: Stop when we reach the desired vocabulary size
Vocabulary: [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs"", ""hu"", ""hug""]
Corpus: (""hug"", 10), (""p"" ""##u"" ""##g"", 5), (""p"" ""##u"" ""##n"", 12), (""b"" ""##u"" 
""##n"", 4), (""hu"" ""##gs"", 5)"
3-llm-tokenization.pdf,32,"The slide contains no technical content related to machine learning or natural language processing to describe. It only indicates the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional affiliation and not a technical concept, algorithm, equation, or architecture.","33
WordPiece Tokenization ‚Äì Training
‚ñ™Training Outcome
(1) Vocabulary [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs"", ""hu"", ""hug""]
(2) Merge Rules 
Difference: only saves the final vocabulary, not the merge rule learned"
3-llm-tokenization.pdf,33,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It only displays the name of a college, ""University of Florida Herbert Wertheim College of Engineering."" There is no explanation or information pertaining to ML/NLP topics on this slide.","34
WordPiece Tokenization ‚Äì Tokenize
‚ñ™Step 1: Finding the longest substring that is in the vocabulary
‚ñ™Step 2: Splitting It
Vocabulary [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs"", ""hu"", ""hug""]
New Word: ""hugs"" -> ""hug"" is the longest substring starting from the 
beginning that is inside the Vocabulary V
               -> split it [""hug"", ""##s""] 
               -> continue with ""##s"" which is already in V"
3-llm-tokenization.pdf,34,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical details to explain from this slide.","35
WordPiece Tokenization ‚Äì Tokenize
‚ñ™Step 1: Finding the longest substring that is in the vocabulary
‚ñ™Step 2: Splitting It
Vocabulary [""b"", ""h"", ""p"", ""##g"", ""##n"", ""##s"", ""##u"", ""##gs"", ""hu"", ""hug""]
New Word: ‚Äùbugs"" -> ‚Äùb"" is the longest substring  
                  -> split it [‚Äùb"", ""##ugs""] 
                  -> continue with ""##ugs‚Äù, ""##u‚Äù is the longest substring 
                                       -> split it [""b"", ""##u, ""##gs""] 
                  -> continue with ""##gs"" which is already in V"
3-llm-tokenization.pdf,35,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There is no technical content related to machine learning or natural language processing concepts, algorithms, or architectures present on this slide.","36
Algorithm 3 ‚Äì Unigram Tokenization"
3-llm-tokenization.pdf,36,"The slide contains only the name of an institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not have any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or their relationships. Therefore, there are no relevant technical details to describe from this slide.","37
Unigram Tokenization
‚ñ™Used by language models like T5, XLNet, ALBERT, Big Bird
‚ñ™Core Idea: Different from BPE and WordPiece that start from a small 
vocabulary and then iteratively expand, it starts from a big vocabulary 
and removes tokens from it until reaching the desired vocabulary size"
3-llm-tokenization.pdf,37,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or their relationships. Therefore, there are no relevant technical details to explain from this slide.","38
Unigram Tokenization ‚Äì Tokenize
‚ñ™Step 1: List out all the possible segmentations of a new word
‚ñ™Step 2: Compute the probability of each possible segmentation based 
on Unigram LM
‚ñ™Step 3: Select the one segmentation with the highest probability as 
the final tokenization"
3-llm-tokenization.pdf,38,"This slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content, concepts, algorithms, equations, architectures, or relationships relevant to machine learning or natural language processing. Therefore, there is no technical content to explain from this slide.","39
Unigram Tokenization ‚Äì Tokenize
‚ñ™Step 1: List out all the possible segmentations of a new word
Example: Final Vocabulary and its corresponding frequency in corpus
(""h"", 15) (""u"", 36) (""g"", 20) (""hu"", 15) (""ug"", 20) (""p"", 17) (""pu"", 17) (""n"", 
16) (""un‚Äù, 16) (""b"", 4) (""bu"", 4) (""s"", 5) (""hug"", 15) (""gs"", 5) (""ugs"", 5)
New Word: ""pug""
All the possible segmentations: [""p"", ""u"", ""g""], [""p"", ""ug""], [""pu"", ""g""]"
3-llm-tokenization.pdf,39,"The slide text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" indicates an institutional affiliation, so there is no technical content like concepts, algorithms, equations, or architectures to explain here.","40
Unigram Tokenization ‚Äì Tokenize
‚ñ™Step 2: Compute the prob of each segmentation based on Unigram LM
Example: Final Vocabulary and its corresponding frequency in corpus
(""h"", 15) (""u"", 36) (""g"", 20) (""hu"", 15) (""ug"", 20) (""p"", 17) (""pu"", 17) (""n"", 
16) (""un‚Äù, 16) (""b"", 4) (""bu"", 4) (""s"", 5) (""hug"", 15) (""gs"", 5) (""ugs"", 5)
New Word: ""pug""
[""p"", ""u"", ""g""] : 0.000389 [""p"", ""ug""] : 0.0022676 [""pu"", ""g""] : 0.0022676"
3-llm-tokenization.pdf,40,"The slide contains only an institutional header: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING.""

There is no technical content related to machine learning, natural language processing, or related concepts such as algorithms, architectures, or equations present on this slide to explain.","41
Unigram Tokenization ‚Äì Tokenize
‚ñ™Step 3: Select the one segmentation with the highest probability as 
the final tokenization
New Word: ""pug""
[""p"", ""u"", ""g""] : 0.000389 [""p"", ""ug""] : 0.0022676 [""pu"", ""g""] : 0.0022676
Choose [""p"", ""ug""] or [""pu"", ""g""] depending on which is encountered first"
3-llm-tokenization.pdf,41,"The slide contains only a header text stating ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","42
Unigram Tokenization ‚Äì Training
‚ñ™Core Idea:
Calculate a loss of corpus based on current vocabulary V
Remove each token from V and re-calculate loss of corpus
Select the token that results in the least increase in loss of corpus
(least change, less effect, less needed, should be removed)"
3-llm-tokenization.pdf,42,"The slide contains no technical content related to machine learning, natural language processing, or related fields. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be an institutional header or footer. There are no concepts, algorithms, equations, architectures, or relationships presented on this slide.","43
Unigram Tokenization ‚Äì Training
‚ñ™Step 1: Starting from a big vocabulary, e.g., listing out all the possible 
substrings in corpus, or applying BPE on the initial corpus with a large 
vocabulary size
Our corpus  (""hug"", 10), (""pug"", 5), (""pun"", 12), (""bun"", 4), (""hugs"", 5)
Initial Vocabulary: [""h"", ""u"", ""g"", ""hu"", ""ug"", ""p"", ""pu"", ""n"", ""un"", ""b"", ""bu"", 
""s"", ""hug"", ""gs"", ""ugs""]"
3-llm-tokenization.pdf,43,"The slide contains no technical content related to machine learning, natural language processing, or related fields. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which refers to an academic institution and its college of engineering. There are no concepts, algorithms, equations, architectures, or relationships presented on this slide.","44
Unigram Tokenization ‚Äì Training
‚ñ™Step 2: Calculate a Loss of corpus by tokenizing every word in the corpus 
‚ñ™Loss of each word = ‚Äì log (P(word)), Loss of corpus = sum(Loss of all 
the word in the corpus)
Our corpus  (""hug"", 10), (""pug"", 5), (""pun"", 12), (""bun"", 4), (""hugs"", 5)
Prob of each word: ""hug"": [""hug""] (score 0.071428) ""pug"": [""pu"", ""g""] (score 
0.007710) ""pun"": [""pu"", ""n""] (score 0.006168) ""bun"": [""bu"", ""n""] (score 0.001451) 
""hugs"": [""hug"", ""s""] (score 0.001701)
Loss of corpus = 10 * (-log(0.071428)) + 5 * (-log(0.007710)) + 12 * (-
log(0.006168)) + 4 * (-log(0.001451)) + 5 * (-log(0.001701)) = 169.8"
3-llm-tokenization.pdf,44,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content related to machine learning, natural language processing, or related concepts to describe.","45
Unigram Tokenization ‚Äì Training
‚ñ™Step 3: For each token in the current vocabulary V, we remove it from 
V, and recalculate the Loss of corpus based on the updated vocabulary
‚ñ™Loss of each word = - log (P(word)), Loss of corpus = sum(Loss of 
all the word in the corpus)
‚ñ™Step 4: Select the token w that results in the least increase in Loss
(Loss of corpus based on vocabulary V‚Äô after removing token w ‚Äì Loss of 
corpus based on vocabulary V before removing w)
Remove this token w from the current vocabulary V and update V"
3-llm-tokenization.pdf,45,"The slide does not contain any technical content, algorithms, equations, architectures, or relationships related to Machine Learning or Natural Language Processing. It simply displays the title ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" likely indicating the institution associated with the course or presentation.","46
Summary of Tokenization Algorithms
‚ñ™Byte-Pair Encoding (BPE) & WordPiece Tokenization
Core Idea: start with each character as the token, and then iteratively 
merge the token pair that co-occur together most often into new token
Difference: vocabulary initialization and frequency score calculation
‚ñ™Unigram Tokenization
Core Idea: start from a big vocabulary and iteratively remove the token 
that results in the least increase in loss of corpus"
3-llm-tokenization.pdf,46,"The slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. It appears to be a background image of a building with a slogan at the bottom reading ""Leading the Charge, Charging Ahead."" There are no visible components such as models, formulas, diagrams, or textual descriptions related to ML/NLP techniques to describe.",Thank you!
3-llm-tokenization.pdf,47,"The slide contains only a textual heading identifying the ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide to explain.","48
References
https://huggingface.co/learn/llm-course/en/chapter6/7?fw=pt
https://medium.com/thedeephub/all-you-need-to-know-about-
tokenization-in-llms-7a801302cf54"
4-feedforward-neural-lm.pdf,0,"There is no technical content such as concepts, algorithms, equations, architectures, or relationships visible on this slide to explain.","CIS 6930 Special Topics in Large Language Models
Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,1,"The slide header simply states the institution name: University of Florida Herbert Wertheim College of Engineering. 

No technical content, concepts, algorithms, or equations related to machine learning or natural language processing are included on this slide to describe or explain.","2
Neural Networks in NLP
From Word Embedding to Neural Networks"
4-feedforward-neural-lm.pdf,2,"The text on this slide is the name of an educational institution, specifically ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP presented on this slide. It serves as an institutional or organizational heading rather than technical content.","3
Neural Networks in NLP
Several Types of Neural Networks in NLP
Feed-forward NNs
Recurrent NNs
Transformers"
4-feedforward-neural-lm.pdf,3,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical content to explain.","4
Outline
‚ñ™Feedforward Neural Networks
‚ñ™Model 1: Neural ‚Äúbag-of-words‚Äù Models
‚ñ™Model 2: Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,4,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","5
Feedforward Neural Networks"
4-feedforward-neural-lm.pdf,5,"The slide content contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical material related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to describe from this slide.","6
Feed-forward Neural Network
‚ñ™The units are connected with no cycles
‚ñ™The outputs from units in each layer are passed to units in the next layer
‚ñ™No outputs are passed back to lower layers
Fully-connected (FC) layers
All the units from one layer are 
fully connected to every unites 
of the next layer"
4-feedforward-neural-lm.pdf,6,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"". It does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical concepts or topics to explain from this slide.","7
Feed-forward Neural Network"
4-feedforward-neural-lm.pdf,7,"The slide does not contain any technical content related to machine learning or natural language processing. It only contains the text ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional name and does not provide any concepts, algorithms, equations, architectures, or relationships relevant to ML/NLP.","8
Activation Functions
‚ñ™For deep neural networks, the first thing to try is ReLU: it trains quickly 
and performs well due to good gradient backflow
‚ñ™Sigmoid and tanh functions are still used (e.g. sigmoid to get probability)"
4-feedforward-neural-lm.pdf,8,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain from this slide.","9
Why Activation Functions
‚ñ™The purpose is to add Non-Linearities into Neural Networks
‚ñ™Neural networks do function approximation, without non-linearities, 
neural networks cannot do anything more than a linear transformation
‚ñ™But with more layers that include non-linearities, neural networks can 
approximate any complex function!"
4-feedforward-neural-lm.pdf,9,"The slide does not contain any technical content related to ML or NLP concepts, algorithms, or architectures. It simply displays the name ""University of Florida Herbert Wertheim College of Engineering,"" which is an institutional header, not a technical topic or concept.","10
Matrix Notations"
4-feedforward-neural-lm.pdf,10,"The slide contains only a header with the text ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, algorithms, or related concepts. Therefore, there are no technical concepts, equations, or architectures to describe from this slide.","11
Practice ‚Äì Feedforward Neural Network"
4-feedforward-neural-lm.pdf,11,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical concepts to explain from this slide.","12
Practice ‚Äì Feedforward Neural Network"
4-feedforward-neural-lm.pdf,12,"The text on this slide indicates the affiliation or institution, specifically the ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing to explain here. If there is additional content or other slides, please provide those for a technical explanation.","13
Training Feedforward Neural Networks
‚ñ™Softmax: applying the softmax function on output logits to get predicted 
probability
‚ñ™Training loss: maximize the probability of the correct class y or 
equivalently we can minimize the negative log probability of that class"
4-feedforward-neural-lm.pdf,13,"The slide contains only a textual header: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or other NLP/ML content presented. Therefore, there is no technical content to explain from this slide.","14
Training Feedforward Neural Networks
‚ñ™Optimizer: stochastic gradient descent (SGD) to train feedforward NN
‚ñ™Neural Networks are difficult to optimize. SGD can only converge to 
local minimum. Initialization and Optimizer matter a lot!
stepping size or learning rate
Model parameters include W  weight matrix and b bias terms between layers
Objective: learn model parameters to minimize loss"
4-feedforward-neural-lm.pdf,14,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional or organizational name. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","15
Training Feedforward NN ‚Äì Back-propagation"
4-feedforward-neural-lm.pdf,15,"The slide contains only a text line stating the institution's name: ""University of Florida Herbert Wertheim College of Engineering"". It does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no ML/NLP technical information to explain from this slide.","16
Training Feedforward NN ‚Äì Back-propagation"
4-feedforward-neural-lm.pdf,16,"The text on the slide states ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

This indicates the institution and college associated with the content but does not contain any technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no technical content to explain from this slide.","17
Neural ‚Äúbag-of-words‚Äù Models
for Text Classification"
4-feedforward-neural-lm.pdf,17,"The slide only contains the text ""University of Florida Herbert Wertheim College of Engineering,"" which is the name of an educational institution. There are no technical terms, concepts, algorithms, or architectures related to machine learning or natural language processing presented on this slide to explain.","18
Comparison: image vs text inputs
‚ñ™Images: fixed-size input, continuous values
‚ñ™Text: variable-length input, discrete words"
4-feedforward-neural-lm.pdf,18,"The slide header indicates the institutional affiliation: University of Florida Herbert Wertheim College of Engineering. However, this does not pertain to any technical content in machine learning or natural language processing itself. There are no technical concepts, algorithms, equations, or architectures presented on this slide. It appears to be a title or affiliation slide rather than a technical content slide.","19
Solution 1: feature vector as input"
4-feedforward-neural-lm.pdf,19,"The slide shown contains only a header indicating the institution name, ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented on this slide to explain.","20
Solution 2: pooling on word embeddings
‚ñ™Aggregate all the word embeddings into a vector via pooling function"
4-feedforward-neural-lm.pdf,20,"The slide content is only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","21
Neural ‚Äúbag-of-words‚Äù Model
Pro:
‚ñ™This provides a simple and flexible way to handle variable-length input
‚ñ™Learns feature representation (word embedding) automatically from data
‚ñ™It can generalize to similar inputs through word embeddings
Cons:
‚ñ™The model throw away any sequential information of the text"
4-feedforward-neural-lm.pdf,21,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning, natural language processing, or related algorithms. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","22
Neural ‚Äúbag-of-words‚Äù Model ‚Äì Training"
4-feedforward-neural-lm.pdf,22,"This slide contains only the name of the institution ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP presented here.","23
Neural ‚Äúbag-of-words‚Äù Model ‚Äì Training
‚ñ™Common practice: initialize word embedding E using static pre-trained 
word embeddings (e.g. word2vec), and optimize them using SGD
‚ñ™When the training data is small, don‚Äôt treat E as parameters
‚ñ™When the training data is very large, initialization does not matter much, 
can use random initialization for word embeddings"
4-feedforward-neural-lm.pdf,23,"The slide contains no technical content related to machine learning or natural language processing. It only displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures presented.","24
Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,24,"The slide contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which does not present any technical NLP or ML content such as concepts, algorithms, architectures, or equations. Hence, there is no technical content related to machine learning or natural language processing to explain from this slide.","25
N-gram vs neural language models
Limitations: cannot handle long histories"
4-feedforward-neural-lm.pdf,25,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There is no technical content related to machine learning, natural language processing, algorithms, equations, or architectures presented on this slide to describe.","26
N-gram vs neural language models
‚ñ™The larger n, the number of possible n-grams grow exponentially
‚ñ™The larger n, the frequency counts for a specific n-gram is more sparse
‚ñ™A lot of contexts are similar and simply counting their frequency cannot 
reflect their sematic similarity
Neural LM mitigates these issues"
4-feedforward-neural-lm.pdf,26,"The slide simply displays the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented to explain.","27
Feedforward Neural Language Models
‚ñ™Key Idea: instead of estimating raw probabilities, let‚Äôs use a feedforward 
neural network to fit the probabilistic distribution of language
‚ñ™Feedforward neural language models approximate the probability based 
on the previous m (e.g. 5) words ‚Äì m is a hyper-parameter"
4-feedforward-neural-lm.pdf,27,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" without any technical content related to machine learning or natural language processing concepts, algorithms, or equations. There are no technical concepts, architectures, or relationships presented on this slide for explanation.","28
Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,28,"The slide contains only a header text stating the institution name: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented on this slide related to machine learning or natural language processing.","29
Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,29,"The slide contains no technical content related to machine learning or natural language processing. It shows the name of an educational institution, ""University of Florida Herbert Wertheim College of Engineering,"" and does not present any concepts, algorithms, architectures, or equations.","30
Feedforward Neural Language Models"
4-feedforward-neural-lm.pdf,30,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, architectures, or equations. Therefore, there is no technical material to explain from this slide.","31
Feedforward Neural Language Models
‚ñ™How to train this model? Use a lot of raw text to create training examples 
and run gradient-descent optimization
‚ñ™Limitations: (1) W linearly scales with the context size m (2) The model 
learns separate patterns for different positions
‚ñ™Better solutions: Recurrent NNs, Transformers
‚Äúsat on‚Äù corresponds to different parameters in W"
4-feedforward-neural-lm.pdf,31,There is no visible technical content on this slide to explain. It appears to be an image of a modern building with no text or graphics related to machine learning or natural language processing concepts. Please provide a slide with technical material for explanation.,Thank you!
5-rnn-lm.pdf,0,"There is no technical content, concepts, equations, algorithms, or architectures visible on this slide to describe. It appears to be a background image with a building and a slogan, and does not contain any NLP or ML material.","CIS 6930 Special Topics in Large Language Models
Recurrent Neural Network for LM"
5-rnn-lm.pdf,1,"The slide header provides the institution name: University of Florida Herbert Wertheim College of Engineering. There is no technical content, concepts, algorithms, or equations related to machine learning or natural language processing presented on the slide.","2
Outline
‚ñ™Recurrent Neural Network (RNN)
‚ñ™Training RNN LM
‚ñ™Inference and Evaluation of RNN LM
‚ñ™Applications of RNN LM
‚ñ™Problems of RNN ‚Äì Vanishing and Exploding Gradients
‚ñ™Variants of RNN ‚Äì LSTM, GRU, Bi-directional RNN, Multi-layer RNN"
5-rnn-lm.pdf,2,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical explanation to provide from this slide.","3
Feedforward Neural Language Model
Fixed window size"
5-rnn-lm.pdf,3,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is an institutional name. There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP present on this slide to describe.","4
Feedforward Neural Language Model
Improvements over n-gram LM:
‚ñ™No sparsity problem
‚ñ™Don‚Äôt need to store all observed n-grams
Problems that still exists:
‚ñ™Fixed window size is small
‚ñ™Window size growth enlarges W
‚ñ™Different W for different positions of tokens
Need a model that can process any length input"
5-rnn-lm.pdf,4,"The content on this slide is a header showing the institution name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP presented on this slide.","5
Recurrent Neural Network"
5-rnn-lm.pdf,5,"The slide contains only a header that states ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing.","6
Recurrent Neural Network
Core Idea: Apply the same weights W repeatedly
RNN can handle variabl
length input"
5-rnn-lm.pdf,6,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not provide any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain from this slide.","7
Recurrent Neural Network"
5-rnn-lm.pdf,7,"The slide contains only the title text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not have any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical concepts to explain from this slide.","8
Recurrent Neural Network"
5-rnn-lm.pdf,8,"The slide content is a header indicating an affiliation: ""University of Florida Herbert Wertheim College of Engineering."" It does not present any technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing.","9
RNN Language Model
Pros
‚ñ™Can process any length input
‚ñ™Memory size not increase for longer input
‚ñ™Can use info from many steps back
‚ñ™Same weights W applied on every position
Cons:
‚ñ™Recurrent computation is slow, no parallel
‚ñ™Hard to access info from many steps back
  (in practice)"
5-rnn-lm.pdf,9,"The slide text shows the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" 

There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide to explain.","10
Training Recurrent Neural Network LM"
5-rnn-lm.pdf,10,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing such as concepts, algorithms, equations, or architectures. Therefore, there is no technical content to explain from this slide.","11
Training RNN LM"
5-rnn-lm.pdf,11,"This slide header shows the affiliation of the course or presentation and does not contain technical content related to machine learning or natural language processing concepts, algorithms, or models. It is an institutional title: ""University of Florida Herbert Wertheim College of Engineering.""","12
Training RNN LM"
5-rnn-lm.pdf,12,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, or architectures. Therefore, there is no technical material to explain from this slide.","13
Training RNN LM"
5-rnn-lm.pdf,13,"The slide only contains a textual header indicating the ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to ML/NLP presented on this slide.","14
Training RNN LM"
5-rnn-lm.pdf,14,"The slide contains only a textual header indicating the affiliation: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. Therefore, there is no technical content to explain from an ML/NLP perspective.","15
Training RNN LM"
5-rnn-lm.pdf,15,"This slide contains only a text heading: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or other NLP/ML content presented on this slide.","16
Training RNN LM"
5-rnn-lm.pdf,16,"The slide appears to only contain the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content, concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing. Therefore, there is no relevant technical content to explain from this slide. If you provide another slide with technical material, I can explain those concepts.","17
Training RNN LM"
5-rnn-lm.pdf,17,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which is the name of an institution. It does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical topics to explain from this slide.","18
Training RNN LM
‚ñ™Computing loss and gradients across entire corpus is too expensive
‚ñ™In practice, consider training on sentence or document
‚ñ™Compute loss ùêΩ(ùúÉ) for a sentence, or a batch of sentences, and 
compute gradients and update weights, iteratively repeat until converge"
5-rnn-lm.pdf,18,"This slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. There are no technical elements to explain from this slide.","19
Backpropagation for RNN"
5-rnn-lm.pdf,19,"The slide contains only a single line of text stating the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or NLP presented on this slide.","20
Backpropagation for RNN
Multivariable Chain Rule"
5-rnn-lm.pdf,20,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not have any technical content related to machine learning or natural language processing to explain.","21
Backpropagation for RNN"
5-rnn-lm.pdf,21,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to ML or NLP concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain from this slide.","22
Backpropagation for RNN
Backpropagation through time
(Backpropagate over timesteps i=t,‚Ä¶,0, 
summing gradients as you go)
In practice, truncate after 20 timesteps for 
training efficiency"
5-rnn-lm.pdf,22,"The content on the slide is a title header indicating the institutional affiliation, specifically the University of Florida Herbert Wertheim College of Engineering. There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing presented on this slide. It serves only to identify the institution associated with the material or presentation.","23
Truncated Backpropagation for RNN"
5-rnn-lm.pdf,23,"The slide contains only a textual header stating ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide to explain.","24
Inference of Recurrent Neural Network LM"
5-rnn-lm.pdf,24,"The slide content is limited to the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" which is the name of an academic institution. There are no technical concepts, algorithms, equations, architectures, or relationships related to ML or NLP presented on this slide.","25
Generating Text with RNN LM
Generate text by repeated sampling. 
Sampled output becomes next step‚Äôs input"
5-rnn-lm.pdf,25,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical material on this slide to explain.","26
Evaluating Recurrent Neural Network LM"
5-rnn-lm.pdf,26,"The slide presents the name of an educational institution, specifically the University of Florida Herbert Wertheim College of Engineering. There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing discussed on this slide. It serves as a title or header rather than instructional content on ML/NLP topics.","27
Evaluation of RNN LM"
5-rnn-lm.pdf,27,"The text on the slide does not convey any technical content related to machine learning or natural language processing. It only indicates the name of the institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships presented here to explain.","28
Evaluation of RNN LM"
5-rnn-lm.pdf,28,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","29
Application of RNN LM"
5-rnn-lm.pdf,29,"This slide contains no technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It appears to be an institutional or header slide displaying the name of the ""University of Florida Herbert Wertheim College of Engineering.""","30
Application 1: Token-level Classification Tasks
Part-of-Speech Tagging, Name Entity Recognition"
5-rnn-lm.pdf,30,"The slide presents the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing to explain here.","31
Application 2: Sentence Classification
Sentiment Classification"
5-rnn-lm.pdf,31,"The slide text itself ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" contains no technical content related to ML or NLP concepts, algorithms, architectures, or equations. It appears to be an institutional or header title rather than explanation or educational material about machine learning or natural language processing topics. 

Please provide another slide or image containing specific technical content for explanation.","32
Application 2: Sentence Classification
Sentiment Classification"
5-rnn-lm.pdf,32,"The slide only contains a textual header stating ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships presented here related to machine learning or natural language processing to explain.","33
Application 2: Sentence Classification
Sentiment Classification"
5-rnn-lm.pdf,33,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not present any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","34
Application 3: RNN as Encoder
Question Answering"
5-rnn-lm.pdf,34,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not provide any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical material to explain.","35
Application 3: RNN as Decoder
Speech Recognition, Machine Translation, Summarization etc."
5-rnn-lm.pdf,35,"The slide contains only the text ""University of Florida Herbert Wertheim College of Engineering."" It does not include any technical content related to machine learning, natural language processing, or relevant concepts such as algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain on this slide.","36
Problems of RNN LM: 
Vanishing and Exploding Gradients"
5-rnn-lm.pdf,36,"The slide contains only a header text identifying the ""University of Florida Herbert Wertheim College of Engineering."" It does not present any technical content related to machine learning, natural language processing, or related algorithms, equations, or architectures. Therefore, there are no technical concepts, algorithms, or relationships to explain from this slide.","37
Vanishing and Exploding Gradients"
5-rnn-lm.pdf,37,"The slide content you provided contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical concepts, algorithms, equations, architectures, or other NLP/ML-related content to explain. 

Please provide a slide or text containing the technical material you would like explained.","38
Vanishing and Exploding Gradients
Gradients grow/shrink 
exponentially"
5-rnn-lm.pdf,38,"The slide only presents the text ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","39
Effect of Vanishing Gradients"
5-rnn-lm.pdf,39,"The slide contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, or architectures related to machine learning or natural language processing presented on this slide. It appears to be an institutional or title slide without technical content to explain.","40
Effect of Vanishing Gradients"
5-rnn-lm.pdf,40,"The slide does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. It only displays the institution name ""University of Florida Herbert Wertheim College of Engineering."" There are no ML/NLP technical details to explain here.","41
Effect of Exploding Gradients"
5-rnn-lm.pdf,41,"The text on this slide is simply the name of an educational institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or related NLP/ML content presented here to explain.","42
Practice of Vanishing / Exploding Gradients"
5-rnn-lm.pdf,42,"The slide only contains the text ""University of Florida Herbert Wertheim College of Engineering"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there are no technical details to explain.","43
Solution for Exploding Gradients"
5-rnn-lm.pdf,43,"The slide contains no technical content to explain. It only shows the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING,"" which appears to be an institutional or college name rather than any NLP or ML concept, algorithm, equation, architecture, or relationship.","44
How to solve Vanishing Gradients"
5-rnn-lm.pdf,44,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There is no technical content such as concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing to explain.","45
Long Short-Term Memory RNN (LSTM)"
5-rnn-lm.pdf,45,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical topics to explain based on this slide.","46
LSTM Core Idea"
5-rnn-lm.pdf,46,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" without any technical content related to machine learning or natural language processing concepts, algorithms, equations, or architectures. Therefore, there is no technical content to explain from this slide.","47
LSTM Architecture"
5-rnn-lm.pdf,47,"The text on the slide ""University of Florida Herbert Wertheim College of Engineering"" is simply a header or institutional affiliation and does not contain technical content related to machine learning or natural language processing concepts, algorithms, or equations. There are no technical concepts, algorithms, architectures, or relationships presented in this text to explain.","48
LSTM Architecture"
5-rnn-lm.pdf,48,"The slide contains only an institutional title: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" It does not include any technical content related to machine learning, natural language processing, or related algorithms, models, or concepts. Therefore, there are no technical concepts, algorithms, equations, architectures, or relationships to explain on this slide.","49
LSTM Architecture"
5-rnn-lm.pdf,49,"The text on the slide is purely the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, or architectures related to machine learning or NLP presented in this image.","50
LSTM Architecture
‚ñ™The LSTM architecture makes it easier for the RNN to preserve 
information over many timesteps 
‚ñ™LSTM doesn‚Äôt guarantee that there is no vanishing/exploding 
gradient, but it does provide an easier way for the model to learn 
long-distance dependencies"
5-rnn-lm.pdf,50,"The slide contains only institutional branding text: ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide.","51
Gated Recurrent Units (GRU)"
5-rnn-lm.pdf,51,"The slide displays the name ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING."" 

There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on this slide. It appears to be an institutional or title slide.","52
LSTM vs GRU"
5-rnn-lm.pdf,52,"The slide only contains text showing the name of an academic institution: ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing presented on the slide.","53
FFNN vs RNN vs LSTM vs GRU"
5-rnn-lm.pdf,53,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain from this slide.","54
Is Vanishing Gradient unique to RNN?"
5-rnn-lm.pdf,54,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not contain any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there is no technical content to explain on this slide.","55
Is Vanishing Gradient unique to RNN?"
5-rnn-lm.pdf,55,"The text on the slide simply states the name of an institution: ""University of Florida Herbert Wertheim College of Engineering."" 

There are no technical concepts, algorithms, equations, architectures, or machine learning/NLP content present to explain.","56
Other RNN Variants"
5-rnn-lm.pdf,56,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing. Therefore, there are no concepts, algorithms, equations, architectures, or relationships to explain.","57
Bi-directional RNN"
5-rnn-lm.pdf,57,"The slide text only contains the name ""University of Florida Herbert Wertheim College of Engineering."" There are no technical concepts, algorithms, equations, architectures, or NLP-related content present to explain. Please provide a slide with specific technical content or details to analyze.","58
Bi-directional RNN"
5-rnn-lm.pdf,58,"The slide only contains the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning or natural language processing concepts, algorithms, equations, architectures, or relationships. Therefore, there are no technical topics to explain.","59
Bi-directional RNN"
5-rnn-lm.pdf,59,"This slide contains no technical content related to machine learning or natural language processing. It only displays the text ""University of Florida Herbert Wertheim College of Engineering,"" which is likely an institutional or affiliation title rather than a technical topic.","60
Bi-directional RNN
‚ñ™Bi-directional RNN is only applicable if you have access to the entire 
input sequence. If you do have entire input sequence, bidirectionality 
is powerful (you should use it by default). 
‚ñ™Bi-directional RNN is not applicable to Language Modeling, because 
in LM you only have left context available. 
‚ñ™Bi-directional RNN can be used as Encoder, not Decoder"
5-rnn-lm.pdf,60,"The slide contains only the text ""UNIVERSITY OF FLORIDA HERBERT WERTHEIM COLLEGE OF ENGINEERING"" and does not include any technical content related to machine learning, natural language processing, or related concepts. Therefore, there are no technical concepts, algorithms, equations, architectures, or relationships to explain from this slide.","61
Practice of Bi-directional RNN"
5-rnn-lm.pdf,61,"The slide contains no technical content related to machine learning or natural language processing. It only displays the institutional name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, or architectures presented to explain.","62
Bi-directional RNN"
5-rnn-lm.pdf,62,"The slide contains no technical content to explain, as it only shows the name ""University of Florida Herbert Wertheim College of Engineering."" There are no concepts, algorithms, equations, architectures, or relationships related to machine learning or natural language processing indicated on the slide.","63
Multi-layer RNNs
The hidden states from 
RNN layer i are the inputs 
to RNN layer i+1"
